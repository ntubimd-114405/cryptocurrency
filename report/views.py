import os
import json
import re
from collections import Counter,defaultdict
from decimal import Decimal
from datetime import date,datetime,timedelta, time


import numpy as np
import pandas as pd
import ta
from sklearn.feature_extraction.text import CountVectorizer,ENGLISH_STOP_WORDS


from django.utils import timezone
from django.conf import settings
from django.shortcuts import render, get_object_or_404,redirect
from django.http import HttpResponse
from django.contrib.auth.decorators import login_required
from django.utils.timezone import now
from django.utils.html import escape
from django.db import IntegrityError
from django.db.models import Min, Max, Sum, DateField
from django.db.models.functions import Cast
from django.urls import reverse
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt

from .models import WeeklyReport,DialogEvaluation
from main.models import CoinHistory,Coin,UserProfile, BitcoinPrice
from news.models import Article
from other.models import FinancialSymbol, FinancialData, Indicator, IndicatorValue, BitcoinMetric, BitcoinMetricData
from agent.models import Questionnaire, Question, AnswerOption, UserAnswer, UserQuestionnaireRecord
from data_analysis.text_generation.chatgpt_api import call_chatgpt
from data_analysis.crypto_ai_agent.news_agent import search_news

from django.http import StreamingHttpResponse, JsonResponse
from django.views.decorators.csrf import csrf_exempt
from django.views.decorators.http import require_http_methods




# 1. Kç·šã€æŠ€è¡“æŒ‡æ¨™æ•¸æ“šç”Ÿæˆï¼ˆKç·š & TAï¼‰-----------
def load_price_data_from_db(coin_id, start_date=None, end_date=None):
    queryset = CoinHistory.objects.filter(coin_id=coin_id)
    name = Coin.objects.get(id=1).coinname

    if start_date:
        queryset = queryset.filter(date__gte=start_date)
    if end_date:
        queryset = queryset.filter(date__lte=end_date)


    queryset = queryset.order_by('-date').values(
        'date', 'open_price', 'high_price', 'low_price', 'close_price', 'volume'
    )[:60*24*120]  # 120å¤©

    df = pd.DataFrame.from_records(queryset)

    if df.empty:
        # ç©ºçµæœæ™‚å›å‚³ç©ºå€¼
        return "", pd.DataFrame()

    df.rename(columns={
        'date': 'Date',
        'open_price': 'Open',
        'high_price': 'High',
        'low_price': 'Low',
        'close_price': 'Close',
        'volume': 'Volume',
    }, inplace=True)

    df['Date'] = pd.to_datetime(df['Date'])
    df.set_index('Date', inplace=True)

    daily_df = df.resample('1D').agg({
        'Open': 'first',
        'High': 'max',
        'Low': 'min',
        'Close': 'last',
        'Volume': 'sum'
    }).dropna().reset_index()

    for col in ['Open', 'High', 'Low', 'Close', 'Volume']:
        daily_df[col] = daily_df[col].astype(float)

    return name, daily_df

# æŠ€è¡“æŒ‡æ¨™è¨ˆç®—
def add_technical_indicators(df):
    if df.empty:
        # å»ºç«‹ç©º DataFrameï¼ŒåŒ…å«å¾ŒçºŒå¯èƒ½æœƒä½¿ç”¨çš„æ¬„ä½ï¼ˆç©ºå‹æ…‹ï¼‰
        empty_df = pd.DataFrame(columns=[
            'rsi', 'macd', 'macd_signal', 'ma20', 'ma60', 
            'Date', 'Date_str', 'Open', 'High', 'Low', 'Close',
            'ohlc', 'rsi_point', 'macd_bar', 'macd_signal_line'
        ])
        return empty_df

    # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
    df['rsi'] = ta.momentum.RSIIndicator(df['Close'], window=14).rsi()
    macd = ta.trend.MACD(df['Close'])
    df['macd'] = macd.macd()
    df['macd_signal'] = macd.macd_signal()
    df['ma20'] = df['Close'].rolling(window=20).mean()
    df['ma60'] = df['Close'].rolling(window=60).mean()

    # å°‡æ—¥æœŸè½‰ç‚ºå­—ä¸²æ ¼å¼ä¾›å‰ç«¯ä½¿ç”¨
    df['Date_str'] = df['Date'].dt.strftime('%Y-%m-%d')

    # å»ºç«‹ç•« K ç·šåœ–ç”¨æ¬„ä½æ ¼å¼
    df['ohlc'] = df.apply(lambda row: {
        'x': row['Date_str'],
        'open': row['Open'],
        'high': row['High'],
        'low': row['Low'],
        'close': row['Close']
    }, axis=1)

    # RSI for æŠ˜ç·šåœ–
    df['rsi_point'] = df.apply(lambda row: {
        'x': row['Date_str'],
        'y': row['rsi']
    }, axis=1)

    # MACD + Signal Line
    df['macd_bar'] = df.apply(lambda row: {
        'x': row['Date_str'],
        'y': row['macd']
    }, axis=1)
    df['macd_signal_line'] = df.apply(lambda row: {
        'x': row['Date_str'],
        'y': row['macd_signal']
    }, axis=1)

    return df
# -----------1. Kç·šã€æŠ€è¡“æŒ‡æ¨™æ•¸æ“šç”Ÿæˆï¼ˆKç·š & TAï¼‰


def get_recent_articles(start, end):
    # å‡è¨­ start å’Œ end æ˜¯ datetime.date æˆ– datetime.datetime ç‰©ä»¶
    # å¦‚æœæ˜¯æ—¥æœŸï¼Œè½‰æˆ timezone-aware datetime çš„å€é–“
    if isinstance(start, (date,)):
        start = timezone.make_aware(datetime.combine(start, datetime.min.time()))
    if isinstance(end, (date,)):
        end = timezone.make_aware(datetime.combine(end, datetime.max.time()))

    articles = Article.objects.filter(time__gte=start, time__lte=end).order_by('-time')
    return articles


# 2. ç†±é–€é—œéµè©è©é »çµ±è¨ˆ-----------
def process_word_frequency_sklearn(news_texts, top_n=30, max_features=1000):
    # è‡ªè¨‚åœç”¨è©ï¼Œå¢åŠ é€šç”¨ç„¡é—œè©ï¼Œä»¥å…å¹²æ“¾æ–‡å­—é›²
    extra_stop_words = {
        's', 'u', 'k', 'its', 'from', 'will', 'be', 'you', 'said', 'about', 'more', 'the',
        'based', 'set', 'up', 'some', 'other', 'any', 'many', 'services', 'receive',
        'story', 'call', 'please', 'in', 'on', 'at', 'by', 'for', 'and', 'or', 'but', 'has',
        'have', 'of', 'to', 'with', 'as', 'is', 'it', 'that', 'this', 'their', 'they', 'them'
        'its', 'from', 'will', 'set', 'you', 'said', 'journalists', 'receive', 'story', 'up',
        'based', 'services', 'be', 'about', 'more', 'million', 'infrastructure', 'platform',
        'coindesk'
    }
    stop_words = list(ENGLISH_STOP_WORDS.union(extra_stop_words))
    
    if isinstance(news_texts, str):
        news_texts = [news_texts]

    if not news_texts or all(not text.strip() for text in news_texts):
        return []

    vectorizer = CountVectorizer(
        stop_words=stop_words,
        max_features=max_features
    )
    word_count_matrix = vectorizer.fit_transform(news_texts)
    feature_names = vectorizer.get_feature_names_out()

    total_counts = word_count_matrix.sum(axis=0).A1

    sorted_indices = total_counts.argsort()[::-1][:top_n]
    keywords = [(feature_names[i], total_counts[i]) for i in sorted_indices]
    results = [(word, int(freq)) for word, freq in keywords]
    return results
# -----------2. ç†±é–€é—œéµè©è©é »çµ±è¨ˆ




# Decimal è½‰ float

def decimal_to_float(data_list):
    return [float(val) if isinstance(val, Decimal) else val for val in data_list]

# ä¸»è¦–åœ–ï¼šweekly report
def full_month_data_view(start_date=None, end_date=None):
    if end_date is None:
        end_date = timezone.now().date()
    if start_date is None:
        start_date = end_date - timedelta(days=120)

    # ğŸ“ˆ FinancialData è³‡æ–™
    financial_qs = FinancialData.objects.select_related('symbol').filter(date__range=(start_date, end_date))
    financial_df = pd.DataFrame(list(financial_qs.values(
        'symbol__symbol', 'symbol__name', 'date',
        'open_price', 'high_price', 'low_price', 'close_price', 'volume'
    )))

    # ğŸ§  IndicatorValue è³‡æ–™
    indicator_qs = IndicatorValue.objects.select_related('indicator') \
        .order_by('-date')

    # åˆ†çµ„ï¼Œæ¯å€‹æŒ‡æ¨™å–æœ€è¿‘ 10 ç­†
    indicator_dict = defaultdict(list)
    for iv in indicator_qs:
        if len(indicator_dict[iv.indicator_id]) < 10:
            indicator_dict[iv.indicator_id].append({
                'indicator__name': iv.indicator.name,
                'indicator__abbreviation': iv.indicator.abbreviation,
                'date': iv.date,
                'value': iv.value
            })

    # å°‡æ‰€æœ‰è³‡æ–™åˆä½µæˆ DataFrame
    all_rows = []
    for rows in indicator_dict.values():
        # æ¯å€‹æŒ‡æ¨™çš„è³‡æ–™æŒ‰ç…§æ—¥æœŸæ­£åºæ’åˆ—
        sorted_rows = sorted(rows, key=lambda x: x['date'])
        all_rows.extend(sorted_rows)

    indicator_df = pd.DataFrame(all_rows)

    # ğŸ”— BitcoinMetricData è³‡æ–™
    bitcoin_qs = BitcoinMetricData.objects.select_related('metric').filter(date__range=(start_date, end_date))
    bitcoin_df = pd.DataFrame(list(bitcoin_qs.values(
        'metric__name', 'metric__unit', 'metric__period', 'date', 'value'
    )))

    # ğŸ“Š è½‰ç‚º JSON å‚³åˆ°æ¨¡æ¿ï¼ˆæˆ–å¯ä»¥ä¹‹å¾Œè½‰ç‚º REST APIï¼‰
    return {
        'financial_data_json': financial_df.to_json(orient='records', date_format='iso'),
        'indicator_data_json': indicator_df.to_json(orient='records', date_format='iso'),
        'bitcoin_data_json': bitcoin_df.to_json(orient='records', date_format='iso'),
    }



@login_required
def report_list(request):
    reports = WeeklyReport.objects.order_by('-year', '-week')

    today = now().date()
    this_year, this_week, _ = today.isocalendar()

    # å¹´ä»½ç¯„åœï¼š2022åˆ°ä»Šå¹´
    year_list = list(range(2022, this_year + 1))

    # å»ºç«‹ä¸€å€‹ dictï¼Œkey: å¹´ï¼Œvalue: è©²å¹´å¯é¸é€±æ•¸åˆ—è¡¨
    weeks_by_year = {}
    for year in year_list:
        if year == this_year:
            weeks_by_year[year] = list(range(1, this_week + 1))  # ä»Šå¹´é™å®šåˆ°æœ¬é€±
        else:
            weeks_by_year[year] = list(range(1, 54))  # å…¶ä»–å¹´ä»½å…¨é€±

    context = {
        'reports': reports,
        'year_list': year_list,
        'weeks_by_year': weeks_by_year,
        'this_year': this_year,
        'this_week': this_week,
    }

    return render(request, 'weekly_report_list.html', context)



def convert_id_and_newline(text: str) -> str:
    # é è™•ç†å…¨å½¢ç¬¦è™Ÿèˆ‡å¤§å°å¯«çµ±ä¸€
    text = text.replace('ï¼ˆ', '(').replace('ï¼‰', ')').replace('ï¼š', ':')
    
    # å®šç¾©æ­£å‰‡ï¼Œæ”¯æ´ï¼š
    # - (id:123)ã€(ID:123)
    # - id:123ã€ID:123
    # - å‰é¢å¯æœ‰å¯ç„¡æ‹¬è™Ÿ
    # - ä¸å€åˆ†å¤§å°å¯«
    pattern = r"[\(]?id:(\d+)[\)]?"  # å…ˆåšç°¡å–®åŒ¹é…ï¼Œå†åšè£œå¼·
    regex = re.compile(pattern, flags=re.IGNORECASE)

    def replace_func(match):
        article_id = match.group(1)
        try:
            url = reverse('news_detail', kwargs={'article_id': article_id})
            return f'<a href="{url}">(id:{article_id})</a>'
        except:
            return f"(id:{article_id})"

    # æ›¿æ›æˆé€£çµ
    replaced_text = regex.sub(replace_func, text)
    # æ›è¡Œè™•ç†
    replaced_text = replaced_text.replace('\n', '<br>')

    return replaced_text


# 3. é€±å ±ç”¢ç”Ÿèˆ‡å¤šæ¨¡çµ„æ•¸æ“šæ•´åˆ-----------
@login_required
def generate_weekly_report(request):
    user = request.user
    today = now().date()
    year = int(request.POST.get("year", today.isocalendar()[0]))
    week = int(request.POST.get("week", today.isocalendar()[1]))
    print(year,week)
    # âœ… æ ¹æ“š year å’Œ week è¨ˆç®—å‡º start_dateï¼ˆé€±ä¸€ï¼‰èˆ‡ end_dateï¼ˆé€±æ—¥ï¼‰
    start_date = date.fromisocalendar(year, week, 1)
    end_date = start_date + timedelta(days=6)

    # é‡æ–°è¨ˆç®—è³‡æ–™
    coin,df = load_price_data_from_db(1,start_date,end_date)  # æˆ– user.idï¼Œè¦–ä½ çš„é‚è¼¯
    
    df = add_technical_indicators(df).tail(30)
    ma20_data = decimal_to_float(df['ma20'].tolist())
    ma60_data = decimal_to_float(df['ma60'].tolist())

    news_summary = search_news(
        "BTC",# ç›®å‰å¯«æ­»
        start_date.strftime("%Y-%m-%d"),
        end_date.strftime("%Y-%m-%d"),
    )
    news_summary_with_links = ""

    # å…ˆå–å‡ºæ‰€æœ‰æ–‡ç«  id
    article_ids = [article_data["id"] for article_data in news_summary]

    # å¾è³‡æ–™åº«æŠ“å°æ‡‰çš„ Article ç‰©ä»¶
    articles = Article.objects.filter(id__in=article_ids)
    articles_dict = {article.id: article for article in articles}

    # ä¾ç…§ news_summary çš„é †åºç”Ÿæˆ HTML
    for article_data in news_summary:
        article_id = article_data["id"]
        article = articles_dict.get(article_id)

        if not article:
            continue  # å¦‚æœè³‡æ–™åº«æ²’æœ‰è©²æ–‡ç« å°±è·³é

        url = reverse('news_detail', kwargs={'article_id': article.id})
        title_html = f'<a href="{url}" target="_blank">{escape(article.title)}</a>'
        date_str = escape(article_data.get("date", ""))
        summary_html = escape(article.summary or "")

    news_summary_with_links = ""

    # å…ˆå–å‡ºæ‰€æœ‰æ–‡ç«  id
    article_ids = [int(article_data["id"]) for article_data in news_summary]

    # å¾è³‡æ–™åº«æŠ“å°æ‡‰çš„ Article ç‰©ä»¶
    articles = Article.objects.filter(id__in=article_ids)
    articles_dict = {article.id: article for article in articles}

    # ä¾ç…§ news_summary çš„é †åºç”Ÿæˆ HTML ä¸¦ç´¯ç©æ–‡å­—
    for article_data in news_summary:
        article_id = int(article_data["id"])
        article = articles_dict.get(article_id)
        if not article:
            continue

        # æ–‡ç« é€£çµ
        url = reverse('news_detail', kwargs={'article_id': article.id})
        title_html = f'<a href="{url}" target="_blank">{escape(article.title)}</a>'

        # æ—¥æœŸ
        date_str = article.time.strftime("%Y-%m-%d %H:%M") if article.time else escape(article_data.get("date", ""))

        # æ–‡ç« åœ–ç‰‡ï¼ˆå°åœ–ï¼‰
        article_image_html = ""
        if article.image_url:
            article_image_html = f'<img src="{article.image_url}" alt="Article Image" class="article-image">'

        # æ–‡ç« æ‘˜è¦
        summary_html = escape(article.summary or "")

        # æƒ…ç·’åˆ†æ•¸
        sentiment_html = f'<div class="sentiment-score">æƒ…ç·’åˆ†æ•¸: {article.sentiment_score:.2f}</div>' if article.sentiment_score else ""

        # çµ„æˆæ–°èå¡ç‰‡ HTML
        news_summary_with_links += f'''
        <div class="news-card">
            <h3>{title_html}</h3>
            <span class="news-date">{date_str}</span>
            <div class="news-body">
                {f'<div class="news-thumb">{article_image_html}</div>' if article_image_html else ''}
                <p class="news-summary">{summary_html}</p>
                {sentiment_html}
            </div>
        </div>
        '''



    # å¾è³‡æ–™åº«æŠ“å–é€™æ®µæ™‚é–“çš„æ–‡ç«  content
    start_datetime = datetime.combine(start_date, time.min)  # 00:00:00
    end_datetime   = datetime.combine(end_date, time.max)    # 23:59:59.999999

    # å¾è³‡æ–™åº«æŠ“æ–‡ç« 
    articles_qs = Article.objects.filter(
        time__range=(start_datetime, end_datetime)
    ).values_list('content', flat=True)

    # éæ¿¾ None æˆ–ç©ºå­—ä¸²
    news_text_list = [content for content in articles_qs if content]

    # åˆä½µæˆå–®ä¸€å­—ä¸²çµ¦è©é »åˆ†æ
    news_text = "\n".join(news_text_list)

    # è¨ˆç®—è©é »
    word_freqs = process_word_frequency_sklearn(news_text)

    data = {
        "MA20": list(ma20_data[-7:]),
        "MA60": list(ma60_data[-7:]),
        "RSI": df['rsi_point'].dropna().tail(7).tolist(),
        "MACD": df['macd_bar'].dropna().tail(7).tolist(),
        "MACD_Signal": df['macd_signal_line'].dropna().tail(7).tolist(),
        "OHLC": df['ohlc'].dropna().tail(7).tolist(),
    }
    formatted = json.dumps(data, ensure_ascii=False)


    coin_analysis = call_chatgpt(
        system="ä½ æ˜¯ä¸€ä½å°ˆæ¥­é‡‘èåˆ†æå¸«ï¼Œè«‹ç”¨ HTML <div> åŒ…è£ä½ çš„æŠ€è¡“åˆ†æè©•è«–ã€‚",
        text=f"""è«‹ä¾æ“šä»¥ä¸‹åŠ å¯†è²¨å¹£ {coin} çš„æŠ€è¡“åˆ†æè³‡æ–™é€²è¡Œç°¡æ½”è©•è«–ï¼Œæè¿°ç›®å‰å¸‚å ´è¶¨å‹¢èˆ‡å¯èƒ½çš„è®ŠåŒ–ï¼Œé¿å…é€ç­†èªªæ˜ï¼Œåªéœ€ç¸½é«”åˆ†æèˆ‡è§£é‡‹ã€‚è«‹è¼¸å‡ºç‚ºä¸€æ®µ HTML <div>...</div>ï¼Œä¸è¦é¡å¤–æ–‡å­—ï¼š
        {formatted}
        """
    ).strip("```").strip("html")
    
    summary = call_chatgpt(
        system="ä½ æ˜¯ä¸€ä½æ“…é•·æ’°å¯«è²¡ç¶“ç¸½çµçš„åˆ†æå¸«ã€‚",
        text=f"""
        è«‹ä½ ä»¥å°ˆæ¥­é‡‘èåˆ†æå¸«å£å»ï¼Œç¶œåˆä»¥ä¸‹å…©éƒ¨åˆ†å…§å®¹ï¼Œæ’°å¯«ä¸€æ®µä¸­æ–‡å¸‚å ´ç¸½çµã€‚  
        è«‹å…ˆç”¨æ®µè½ç°¡çŸ­ä»‹ç´¹å¸‚å ´ç‹€æ³ï¼Œ  
        æ¥è‘—ç”¨ HTML çš„ <table> å…ƒç´ ï¼Œå»ºç«‹ä¸€å€‹å…©æ¬„çš„è¡¨æ ¼ï¼Œ  
        å·¦æ¬„æ¨™é¡Œç‚ºã€Œåˆ©å¤šå› ç´ ã€ï¼Œå³æ¬„æ¨™é¡Œç‚ºã€Œåˆ©ç©ºå› ç´ ã€ï¼Œ  
        æ•´æ®µå…§å®¹ç”¨ <div> åŒ…èµ·ä¾†ï¼Œä¸”ä¸è¦é¡å¤–æ–‡å­—ã€‚

        1. æŠ€è¡“åˆ†æè©•è«–ï¼š
        {coin_analysis}

        2. è¿‘æœŸæ–°èæ‘˜è¦ï¼š
        {news_summary}
        """
    ).strip("```").strip("html").strip()

    # ğŸ“Š ä¸­é•·æœŸè§€é»è³‡æ–™æ•´åˆ
    monthly_data = full_month_data_view()
    financial_json = monthly_data['financial_data_json']
    indicator_json = monthly_data['indicator_data_json']
    bitcoin_json = monthly_data['bitcoin_data_json']

    long_term_analysis = call_chatgpt(
        system="ä½ æ˜¯ä¸€ä½é‡‘èå¸‚å ´ç ”ç©¶å“¡ï¼Œè«‹æ’°å¯«ä¸­é•·æœŸè§€å¯Ÿèˆ‡è¶¨å‹¢é æ¸¬ã€‚",
        text=f"""
        è«‹ä½ ä»¥é‡‘èåˆ†æå¸«èº«ä»½ï¼Œæ ¹æ“šä»¥ä¸‹ä¸‰é¡è³‡æ–™ï¼Œæ’°å¯«ä¸€æ®µç´”æ–‡å­—æ ¼å¼çš„ä¸­é•·æœŸå¸‚å ´è§€å¯Ÿèˆ‡è¶¨å‹¢é æ¸¬åˆ†æã€‚
        è«‹é¿å…é€ç­†åˆ—èˆ‰è³‡æ–™ï¼Œåƒ…éœ€å¾ç¸½é«”å±¤é¢åšå‡ºè§£é‡‹èˆ‡é æ¸¬ï¼Œèªæ°£è«‹ä¿æŒå®¢è§€ã€å°ˆæ¥­ï¼Œé¿å…ä½¿ç”¨éå¤šä¸ç¢ºå®šè©ã€‚
        è«‹ç›´æ¥è¼¸å‡ºæ–‡å­—ï¼Œä¸è¦ä½¿ç”¨ HTML æ ¼å¼èˆ‡é¡å¤–æ¨™è¨˜ã€‚
        è³‡æ–™å¦‚ä¸‹ï¼š
        1. é‡‘èåƒ¹æ ¼è³‡æ–™ï¼ˆfinancial_data_jsonï¼‰ï¼š
        {financial_json[:100]}

        2. å®è§€æŒ‡æ¨™è³‡æ–™ï¼ˆindicator_data_jsonï¼‰ï¼š
        {indicator_json[:100]}

        3. æ¯”ç‰¹å¹£éˆä¸ŠæŒ‡æ¨™è³‡æ–™ï¼ˆbitcoin_data_jsonï¼‰ï¼š
        {bitcoin_json[:100]}
        """
    ).strip("```").strip("html").strip()
# -----------3. é€±å ±ç”¢ç”Ÿèˆ‡å¤šæ¨¡çµ„æ•¸æ“šæ•´åˆ
    from django.utils import timezone
    import math
    import pandas as pd

    def clean_indicator(value, default=None):
        """
        å°‡æŒ‡æ¨™æˆ–è³‡æ–™æ¸…ç†æˆåˆæ³•æ ¼å¼ï¼Œé¿å… NaN æˆ– None å‚³å…¥ JSONField
        - å¯ä»¥è™•ç†å–®å€¼ float/int
        - list
        - DataFrame Series
        - list of dict (å°‡ dict å…§çš„ float NaN è½‰æˆ default)
        - dict
        """
        if default is None:
            if isinstance(value, dict):
                default = {}
            elif isinstance(value, list):
                default = []
            else:
                default = 0.0

        if value is None:
            return default

        # DataFrame Series
        if isinstance(value, pd.Series):
            value = value.dropna().tolist()

        # list è™•ç†
        if isinstance(value, list):
            cleaned = []
            for v in value:
                if isinstance(v, dict):
                    new_dict = {}
                    for k, val in v.items():
                        if isinstance(val, float) and math.isnan(val):
                            new_dict[k] = default
                        else:
                            new_dict[k] = val
                    cleaned.append(new_dict)
                elif isinstance(v, float) and math.isnan(v):
                    cleaned.append(default)
                else:
                    cleaned.append(v)
            return cleaned

        # dict è™•ç†
        if isinstance(value, dict):
            new_dict = {}
            for k, val in value.items():
                if isinstance(val, float) and math.isnan(val):
                    new_dict[k] = default
                else:
                    new_dict[k] = val
            return new_dict

        # å–®ä¸€ float è™•ç†
        if isinstance(value, float) and math.isnan(value):
            return default

        return value

    # æ›´æ–°æˆ–æ–°å¢ WeeklyReport
    WeeklyReport.objects.update_or_create(
        user=user,
        year=year,
        week=week,
        defaults={
            'start_date': start_date or timezone.now().date(),
            'end_date': end_date or timezone.now().date(),
            'summary': summary or "",
            'news_summary': news_summary_with_links or "",
            'word_frequencies': clean_indicator(word_freqs, {}),
            'ma20_data': clean_indicator(ma20_data, []),
            'ma60_data': clean_indicator(ma60_data, []),
            'ohlc_data': clean_indicator(df.get('ohlc', []), []),
            'rsi_data': clean_indicator(df.get('rsi_point', []), []),
            'macd_data': clean_indicator(df.get('macd_bar', []), []),
            'macd_signal_data': clean_indicator(df.get('macd_signal_line', []), []),
            'coin_analysis': coin_analysis or "",
            'financial_data_json': clean_indicator(financial_json, {}),
            'indicator_data_json': clean_indicator(indicator_json, {}),
            'bitcoin_data_json': clean_indicator(bitcoin_json, {}),
            'long_term_analysis': long_term_analysis or "",
        }
    )

    return redirect('weekly_report_list')



def generate_weekly_report2(year, week):
    today = now().date()
    print(year, week)
    # æ ¹æ“š year å’Œ week è¨ˆç®—å‡º start_dateï¼ˆé€±ä¸€ï¼‰èˆ‡ end_dateï¼ˆé€±æ—¥ï¼‰
    start_date = date.fromisocalendar(year, week, 1)
    end_date = start_date + timedelta(days=6)
    # å¦‚æœ end_date è¶…éä»Šå¤©ï¼Œæ”¹ç”¨ä»Šå¤©
    if end_date > today:
        end_date = today

    # é‡æ–°è¨ˆç®—è³‡æ–™
    coin,df = load_price_data_from_db(1,start_date,end_date)  
    

    df = add_technical_indicators(df).tail(30)
    ma20_data = decimal_to_float(df['ma20'].tolist())
    ma60_data = decimal_to_float(df['ma60'].tolist())


    news_summary = search_news(
        "BTC",# ç›®å‰å¯«æ­»
        start_date.strftime("%Y-%m-%d"),
        end_date.strftime("%Y-%m-%d"),
    )
    news_summary_with_links = ""

    # å…ˆå–å‡ºæ‰€æœ‰æ–‡ç«  id
    article_ids = [article_data["id"] for article_data in news_summary]

    # å¾è³‡æ–™åº«æŠ“å°æ‡‰çš„ Article ç‰©ä»¶
    articles = Article.objects.filter(id__in=article_ids)
    articles_dict = {article.id: article for article in articles}

    # ä¾ç…§ news_summary çš„é †åºç”Ÿæˆ HTML
    for article_data in news_summary:
        article_id = article_data["id"]
        article = articles_dict.get(article_id)

        if not article:
            continue  # å¦‚æœè³‡æ–™åº«æ²’æœ‰è©²æ–‡ç« å°±è·³é

        url = reverse('news_detail', kwargs={'article_id': article.id})
        title_html = f'<a href="{url}" target="_blank">{escape(article.title)}</a>'
        date_str = escape(article_data.get("date", ""))
        summary_html = escape(article.summary or "")

    news_summary_with_links = ""

    # å…ˆå–å‡ºæ‰€æœ‰æ–‡ç«  id
    article_ids = [int(article_data["id"]) for article_data in news_summary]

    # å¾è³‡æ–™åº«æŠ“å°æ‡‰çš„ Article ç‰©ä»¶
    articles = Article.objects.filter(id__in=article_ids)
    articles_dict = {article.id: article for article in articles}

    # ä¾ç…§ news_summary çš„é †åºç”Ÿæˆ HTML ä¸¦ç´¯ç©æ–‡å­—
    for article_data in news_summary:
        article_id = int(article_data["id"])
        article = articles_dict.get(article_id)
        if not article:
            continue

        # æ–‡ç« é€£çµ
        url = reverse('news_detail', kwargs={'article_id': article.id})
        title_html = f'<a href="{url}" target="_blank">{escape(article.title)}</a>'

        # æ—¥æœŸ
        date_str = article.time.strftime("%Y-%m-%d %H:%M") if article.time else escape(article_data.get("date", ""))

        # æ–‡ç« åœ–ç‰‡ï¼ˆå°åœ–ï¼‰
        article_image_html = ""
        if article.image_url:
            article_image_html = f'<img src="{article.image_url}" alt="Article Image" class="article-image">'

        # æ–‡ç« æ‘˜è¦
        summary_html = escape(article.summary or "")

        # æƒ…ç·’åˆ†æ•¸
        sentiment_html = f'<div class="sentiment-score">æƒ…ç·’åˆ†æ•¸: {article.sentiment_score:.2f}</div>' if article.sentiment_score else ""

        # çµ„æˆæ–°èå¡ç‰‡ HTML
        news_summary_with_links += f'''
        <div class="news-card">
            <h3>{title_html}</h3>
            <span class="news-date">{date_str}</span>
            <div class="news-body">
                {f'<div class="news-thumb">{article_image_html}</div>' if article_image_html else ''}
                <p class="news-summary">{summary_html}</p>
                {sentiment_html}
            </div>
        </div>
        '''



    # å¾è³‡æ–™åº«æŠ“å–é€™æ®µæ™‚é–“çš„æ–‡ç«  content
    start_datetime = datetime.combine(start_date, time.min)  # 00:00:00
    end_datetime   = datetime.combine(end_date, time.max)    # 23:59:59.999999

    # å¾è³‡æ–™åº«æŠ“æ–‡ç« 
    articles_qs = Article.objects.filter(
        time__range=(start_datetime, end_datetime)
    ).values_list('content', flat=True)

    # éæ¿¾ None æˆ–ç©ºå­—ä¸²
    news_text_list = [content for content in articles_qs if content]

    # åˆä½µæˆå–®ä¸€å­—ä¸²çµ¦è©é »åˆ†æ
    news_text = "\n".join(news_text_list)

    # è¨ˆç®—è©é »
    word_freqs = process_word_frequency_sklearn(news_text)

    # çµ±è¨ˆæœ‰ sentiment_score çš„æ–‡ç« æ•¸ï¼Œåˆ†ä¸­ç«‹ã€æ­£é¢ã€è² é¢
    sentiment_counts = {
        'positive': 0,  # ä¾‹å¦‚ sentiment_score > 0.6
        'neutral': 0,   # sentiment_scoreä»‹æ–¼0.4~0.6
        'negative': 0   # sentiment_score < 0.4
    }

    for article in articles_qs:
        score = article['sentiment_score']
        if score is not None:
            if score > 0.1:
                sentiment_counts['positive'] += 1
            elif score < -0.1:
                sentiment_counts['negative'] += 1
            else:
                sentiment_counts['neutral'] += 1

    sentiment_counts_json = json.dumps(sentiment_counts, ensure_ascii=False)
    data = {
        "MA20": list(ma20_data[-7:]),
        "MA60": list(ma60_data[-7:]),
        "RSI": df['rsi_point'].dropna().tail(7).tolist(),
        "MACD": df['macd_bar'].dropna().tail(7).tolist(),
        "MACD_Signal": df['macd_signal_line'].dropna().tail(7).tolist(),
        "OHLC": df['ohlc'].dropna().tail(7).tolist(),
    }
    formatted = json.dumps(data, ensure_ascii=False)


    coin_analysis = call_chatgpt(
        system="ä½ æ˜¯ä¸€ä½å°ˆæ¥­é‡‘èåˆ†æå¸«ï¼Œè«‹ç”¨ HTML <div> åŒ…è£ä½ çš„æŠ€è¡“åˆ†æè©•è«–ã€‚",
        text=f"""è«‹ä¾æ“šä»¥ä¸‹åŠ å¯†è²¨å¹£ {coin} çš„æŠ€è¡“åˆ†æè³‡æ–™é€²è¡Œç°¡æ½”è©•è«–ï¼Œæè¿°ç›®å‰å¸‚å ´è¶¨å‹¢èˆ‡å¯èƒ½çš„è®ŠåŒ–ï¼Œé¿å…é€ç­†èªªæ˜ï¼Œåªéœ€ç¸½é«”åˆ†æèˆ‡è§£é‡‹ã€‚è«‹è¼¸å‡ºç‚ºä¸€æ®µ HTML <div>...</div>ï¼Œä¸è¦é¡å¤–æ–‡å­—ï¼š
        {formatted}
        """
    ).strip("```").strip("html")
    

    # ğŸ“Š ä¸­é•·æœŸè§€é»è³‡æ–™æ•´åˆ
    monthly_data = full_month_data_view(start_date,end_date)
    financial_json = monthly_data['financial_data_json']
    indicator_json = monthly_data['indicator_data_json']
    bitcoin_json = monthly_data['bitcoin_data_json']

    long_term_analysis = call_chatgpt(
        system="ä½ æ˜¯ä¸€ä½é‡‘èå¸‚å ´ç ”ç©¶å“¡ï¼Œè«‹æ’°å¯«ä¸­é•·æœŸè§€å¯Ÿèˆ‡è¶¨å‹¢é æ¸¬ã€‚",
        text=f"""
        è«‹ä½ ä»¥é‡‘èåˆ†æå¸«èº«ä»½ï¼Œæ ¹æ“šä»¥ä¸‹ä¸‰é¡è³‡æ–™ï¼Œæ’°å¯«ä¸€æ®µç´”æ–‡å­—æ ¼å¼çš„ä¸­é•·æœŸå¸‚å ´è§€å¯Ÿèˆ‡è¶¨å‹¢é æ¸¬åˆ†æã€‚
        è«‹é¿å…é€ç­†åˆ—èˆ‰è³‡æ–™ï¼Œåƒ…éœ€å¾ç¸½é«”å±¤é¢åšå‡ºè§£é‡‹èˆ‡é æ¸¬ï¼Œèªæ°£è«‹ä¿æŒå®¢è§€ã€å°ˆæ¥­ï¼Œé¿å…ä½¿ç”¨éå¤šä¸ç¢ºå®šè©ã€‚
        è«‹ç›´æ¥è¼¸å‡ºæ–‡å­—ï¼Œä¸è¦ä½¿ç”¨ HTML æ ¼å¼èˆ‡é¡å¤–æ¨™è¨˜ã€‚
        è³‡æ–™å¦‚ä¸‹ï¼š
        1. é‡‘èåƒ¹æ ¼è³‡æ–™ï¼ˆfinancial_data_jsonï¼‰ï¼š
        {financial_json[:100]}

        2. å®è§€æŒ‡æ¨™è³‡æ–™ï¼ˆindicator_data_jsonï¼‰ï¼š
        {indicator_json[:100]}

        3. æ¯”ç‰¹å¹£éˆä¸ŠæŒ‡æ¨™è³‡æ–™ï¼ˆbitcoin_data_jsonï¼‰ï¼š
        {bitcoin_json[:100]}
        """
    ).strip("```").strip("html").strip()

    summary = call_chatgpt(
        system="ä½ æ˜¯ä¸€ä½æ“…é•·æ’°å¯«è²¡ç¶“ç¸½çµçš„åˆ†æå¸«ã€‚",
        text=f"""
        è«‹ä½ ä»¥å°ˆæ¥­é‡‘èåˆ†æå¸«å£å»ï¼Œç¶œåˆä»¥ä¸‹å…©éƒ¨åˆ†å…§å®¹ï¼Œæ’°å¯«ä¸€æ®µä¸­æ–‡å¸‚å ´ç¸½çµã€‚  
        è«‹å…ˆç”¨æ®µè½ç°¡çŸ­ä»‹ç´¹å¸‚å ´ç‹€æ³ï¼Œ  
        æ¥è‘—ç”¨ HTML çš„ <table> å…ƒç´ ï¼Œå»ºç«‹ä¸€å€‹å…©æ¬„çš„è¡¨æ ¼ï¼Œ  
        å·¦æ¬„æ¨™é¡Œç‚ºã€Œåˆ©å¤šå› ç´ ã€ï¼Œå³æ¬„æ¨™é¡Œç‚ºã€Œåˆ©ç©ºå› ç´ ã€ï¼Œ  
        æ•´æ®µå…§å®¹ç”¨ <div> åŒ…èµ·ä¾†ï¼Œä¸”ä¸è¦é¡å¤–æ–‡å­—ã€‚

        1. æŠ€è¡“åˆ†æè©•è«–ï¼š
        {coin_analysis}

        2. è¿‘æœŸæ–°èæ‘˜è¦ï¼š
        {news_summary}

        3. è¿‘æœŸæ–°èæƒ…ç·’åˆ†é¡æ•¸æ“šï¼š
        {sentiment_counts}
        
        4. é•·æœŸå¸‚å ´è§€å¯Ÿï¼š
        {long_term_analysis}
        """
    ).strip("```").strip("html").strip()
# -----------3. é€±å ±ç”¢ç”Ÿèˆ‡å¤šæ¨¡çµ„æ•¸æ“šæ•´åˆ
    from django.utils import timezone
    import math
    import pandas as pd

    def clean_indicator(value, default=None):
        """
        å°‡æŒ‡æ¨™æˆ–è³‡æ–™æ¸…ç†æˆåˆæ³•æ ¼å¼ï¼Œé¿å… NaN æˆ– None å‚³å…¥ JSONField
        - å¯ä»¥è™•ç†å–®å€¼ float/int
        - list
        - DataFrame Series
        - list of dict (å°‡ dict å…§çš„ float NaN è½‰æˆ default)
        - dict
        """
        if default is None:
            if isinstance(value, dict):
                default = {}
            elif isinstance(value, list):
                default = []
            else:
                default = 0.0

        if value is None:
            return default

        # DataFrame Series
        if isinstance(value, pd.Series):
            value = value.dropna().tolist()

        # list è™•ç†
        if isinstance(value, list):
            cleaned = []
            for v in value:
                if isinstance(v, dict):
                    new_dict = {}
                    for k, val in v.items():
                        if isinstance(val, float) and math.isnan(val):
                            new_dict[k] = default
                        else:
                            new_dict[k] = val
                    cleaned.append(new_dict)
                elif isinstance(v, float) and math.isnan(v):
                    cleaned.append(default)
                else:
                    cleaned.append(v)
            return cleaned

        # dict è™•ç†
        if isinstance(value, dict):
            new_dict = {}
            for k, val in value.items():
                if isinstance(val, float) and math.isnan(val):
                    new_dict[k] = default
                else:
                    new_dict[k] = val
            return new_dict

        # å–®ä¸€ float è™•ç†
        if isinstance(value, float) and math.isnan(value):
            return default

        return value

    # æ›´æ–°æˆ–æ–°å¢ WeeklyReport
    WeeklyReport.objects.update_or_create(
        year=year,
        week=week,
        defaults={
            'start_date': start_date or timezone.now().date(),
            'end_date': end_date or timezone.now().date(),
            'summary': summary or "",
            'news_summary': news_summary_with_links or "",
            'word_frequencies': clean_indicator(word_freqs, {}),
            'ma20_data': clean_indicator(ma20_data, []),
            'ma60_data': clean_indicator(ma60_data, []),
            'ohlc_data': clean_indicator(df.get('ohlc', []), []),
            'rsi_data': clean_indicator(df.get('rsi_point', []), []),
            'macd_data': clean_indicator(df.get('macd_bar', []), []),
            'macd_signal_data': clean_indicator(df.get('macd_signal_line', []), []),
            'coin_analysis': coin_analysis or "",
            'financial_data_json': clean_indicator(financial_json, {}),
            'indicator_data_json': clean_indicator(indicator_json, {}),
            'bitcoin_data_json': clean_indicator(bitcoin_json, {}),
            'long_term_analysis': long_term_analysis or "",
            'sentiment_counts_json': sentiment_counts_json,  # æ–°å¢æ¬„ä½å­˜JSON
        }
    )





def my_favorite_coins_view(request):
    # å–å¾—ä½¿ç”¨è€…æœ€æ„›å¹£ç¨®åŠå…¶æœ€æ–°åƒ¹æ ¼
    favorite_coins = request.user.profile.favorite_coin.all()
    latest_prices = {}
    for coin in favorite_coins:
        price_obj = BitcoinPrice.objects.filter(coin=coin).order_by('-timestamp').first()
        if price_obj:
            latest_prices[coin.id] = price_obj

    watchlist = []
    for coin in favorite_coins:
        price = latest_prices.get(coin.id)
        if price:
            watchlist.append({
                'name': coin.coinname,
                'symbol': coin.abbreviation,
                'price': f"{price.usd:,.2f}",
                'change_24h': float(price.change_24h or 0),
                'market_cap': f"{price.market_cap:,.0f}" if price.market_cap else 'N/A',
            })
        else:
            watchlist.append({
                'name': coin.coinname,
                'symbol': coin.abbreviation,
                'price': 'N/A',
                'change_24h': 0,
                'market_cap': 'N/A',
            })
    return watchlist

@login_required
def view_weekly_report_by_id(request, report_id):
    report = get_object_or_404(WeeklyReport, id=report_id)

    context = {
        'summary': report.summary,
        'news_summary': report.news_summary,
        'word_freqs_json': json.dumps(report.word_frequencies),
        'ma20_data': json.dumps(report.ma20_data),
        'ma60_data': json.dumps(report.ma60_data),
        'ohlc_json': json.dumps(report.ohlc_data),
        'rsi_json': json.dumps(report.rsi_data),
        'macd_json': json.dumps(report.macd_data),
        'macd_signal_json': json.dumps(report.macd_signal_data),
        'coin_analysis':report.coin_analysis,
        'financial_data_json': report.financial_data_json,
        'indicator_data_json': report.indicator_data_json,
        'bitcoin_data_json': report.bitcoin_data_json,
        'long_term_analysis': report.long_term_analysis,
        'sentiment_counts_json': json.dumps(report.sentiment_counts_json),
        'year': report.year,
        'week': report.week,
        'start_date': report.start_date,
        'end_date': report.end_date,
        'created_at': report.created_at,
        'watchlist': my_favorite_coins_view(request),  # <-- åŠ å…¥é€™è¡Œ
    }

    return render(request, 'weekly_report.html', context)


def parse_coin_from_input(user_input):
    """
    ç”¨ GPT è§£æä½¿ç”¨è€…è¼¸å…¥çš„å¹£ç¨®ã€‚
    å¦‚æœæ²’æœ‰æåˆ°ï¼Œé è¨­å›å‚³ 'BTC'ã€‚
    """
    prompt = f"""
    ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„åŠ å¯†è²¨å¹£åŠ©ç†ã€‚
    ä½¿ç”¨è€…æœƒè¼¸å…¥ä¸€å¥è©±ï¼Œå¯èƒ½æœƒæåˆ°æƒ³æŸ¥çš„å¹£ç¨®ï¼Œä¾‹å¦‚ã€Œæ¯”ç‰¹å¹£ã€BTCã€bitcoinã€ä»¥å¤ªåŠã€ETHã€solanaã€ç­‰ã€‚
    å¦‚æœæœ‰æåˆ°å¹£ç¨®ï¼Œè«‹å›å‚³å°æ‡‰çš„å¸¸ç”¨ä»£è™Ÿï¼ˆsymbolï¼‰ï¼Œä¾‹å¦‚ï¼š
    - æ¯”ç‰¹å¹£ â†’ BTC
    - ä»¥å¤ªåŠ â†’ ETH
    - ç‹—ç‹—å¹£ â†’ DOGE
    - Solana â†’ SOL
    - å…¶ä»–å°±å›å‚³æœ€å¸¸è¦‹çš„äº¤æ˜“æ‰€ä»£è™Ÿ
    
    å¦‚æœæ²’æœ‰æåˆ°ä»»ä½•å¹£ç¨®ï¼Œè«‹å›å‚³ "BTC"ã€‚
    
    ä½¿ç”¨è€…è¼¸å…¥ï¼š{user_input}
    
    è«‹åªè¼¸å‡ºä»£è™Ÿï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
    """

    result = call_chatgpt("ä½ æ˜¯ä¸€å€‹å¹£ç¨®è§£æåŠ©ç†", prompt)
    coin_symbol = result.strip().upper()
    return coin_symbol if coin_symbol else "BTC"




def parse_safe_date(date_str):
    """å°‡å­—ä¸²è½‰æˆ dateï¼Œå¤±æ•—å›å‚³ None"""
    if not date_str:
        return None
    try:
        return datetime.strptime(date_str, "%Y-%m-%d").date()
    except Exception:
        return None
    
# 5. å„é¡æ™ºèƒ½åˆ†æå°æ¨¡çµ„ï¼ˆåƒ¹æ ¼ã€æ–°èã€å…¶ä»–æ•¸æ“šã€å•å·ï¼‰-----------
# åƒ¹æ ¼åˆ†ææ¨¡çµ„
def run_price_agent(user, user_input, start_date=None, end_date=None):
    coin_symbol = parse_coin_from_input(user_input)
    # ç¢ºèªå¹£ç¨®å­˜åœ¨
    if not Coin.objects.filter(abbreviation=coin_symbol).exists():
        return {"text": f"âš ï¸ æŠ±æ­‰ï¼Œç³»çµ±å…§æ²’æœ‰æ‰¾åˆ° {coin_symbol} çš„è³‡æ–™ã€‚", "extra_data": [],"analyze" : ""}

    qs = CoinHistory.objects.filter(coin__abbreviation=coin_symbol)
    if not qs.exists():
        return {"text": f"âš ï¸ æ¨¡çµ„ price åŸ·è¡Œå¤±æ•—ï¼š{coin_symbol} æš«ç„¡è³‡æ–™", "extra_data": [],"analyze" : ""}

    # å®‰å…¨è½‰æ›å‚³å…¥æ—¥æœŸ
    if start_date:
        start_date = parse_safe_date(str(start_date))
    if end_date:
        end_date = parse_safe_date(str(end_date))

    # å¦‚æœæ²’å‚³æ—¥æœŸæˆ–è§£æå¤±æ•— â†’ ç”¨è³‡æ–™åº«æœ€æ–° 7 å¤©æœ‰è³‡æ–™çš„æ—¥æœŸ
    if start_date is None or end_date is None:
        latest_days = (
            qs.annotate(day=Cast("date", output_field=DateField()))
            .values("day")
            .distinct()
            .order_by("-day")[:7]
        )
        latest_days = sorted([d["day"] for d in latest_days])
        if not latest_days:
            return {"text": f"âš ï¸ æ¨¡çµ„ price åŸ·è¡Œå¤±æ•—ï¼š{coin_symbol} æš«ç„¡è³‡æ–™", "extra_data": [],"analyze" : ""}
        start_date = latest_days[0]
        end_date = latest_days[-1]

    # èšåˆæŸ¥è©¢
    queryset = qs.annotate(day=Cast("date", output_field=DateField())) \
             .filter(day__gte=start_date, day__lte=end_date)
    daily_range = (
        queryset.annotate(day=Cast("date", output_field=DateField()))
        .values("day", "coin__coinname")
        .annotate(
            first_time=Min("date"),
            last_time=Max("date"),
            high_price=Max("high_price"),
            low_price=Min("low_price"),
            volume=Sum("volume"),
        )
        .order_by("day")
    )
    results = []
    for d in daily_range:
        first_record = qs.filter(date=d["first_time"]).first()
        last_record = qs.filter(date=d["last_time"]).first()
        results.append({
            "day": d["day"].strftime("%Y-%m-%d"),
            "coin": d["coin__coinname"],
            "open": float(first_record.open_price) if first_record else None,
            "high": float(d["high_price"]),
            "low": float(d["low_price"]),
            "close": float(last_record.close_price) if last_record else None,
            "volume": float(d["volume"]),
        })

    if not results:
        return {"text": f"âš ï¸ æ¨¡çµ„ price åŸ·è¡Œå¤±æ•—ï¼š{coin_symbol} åœ¨ {start_date} è‡³ {end_date} ä¹‹é–“æ²’æœ‰è³‡æ–™", "extra_data": [],"analyze" : ""}

    # ç”Ÿæˆ prompt
    analysis_prompt = f"""
    ä½ æ˜¯ä¸€å€‹å°ˆæ¥­åŠ å¯†è²¨å¹£åˆ†æå¸«ã€‚è«‹å¹«æˆ‘åˆ†æä»¥ä¸‹æ¯”ç‰¹å¹£äº¤æ˜“æ•¸æ“šï¼š
    {results}

    è«‹åˆ†ææ¯ä¸€å¤©çš„åƒ¹æ ¼èµ°å‹¢ï¼ˆé–‹ç›¤ã€æ”¶ç›¤ã€æœ€é«˜ã€æœ€ä½ï¼‰ã€äº¤æ˜“é‡è®ŠåŒ–ï¼Œä»¥åŠæ•´é«”è¶¨å‹¢ç‰¹å¾µã€‚
    è«‹æä¾›ï¼š
    1. åƒ¹æ ¼è¶¨å‹¢åˆ†æï¼ˆä¸Šå‡ã€ä¸‹é™ã€ç›¤æ•´ï¼‰
    2. äº¤æ˜“é‡è®ŠåŒ–è¶¨å‹¢
    3. ç¸½é«”è§€å¯Ÿèˆ‡çŸ­æœŸé æ¸¬
    è«‹ç”¨ç°¡æ˜æ‰¼è¦çš„æ–‡å­—åˆ—å‡ºã€‚
    """

    analyze = call_chatgpt("æ¯”ç‰¹å¹£åƒ¹æ ¼åˆ†æå¸«", analysis_prompt).replace("\n", "<br>")

    return {"text": f"ğŸ’°â˜…åƒ¹æ ¼æ¨¡å¡Š", "extra_data": results,"analyze" : analyze}

# æ–°èæ¨¡çµ„
def run_news_agent(user, user_input, start_date=None, end_date=None):

    """
    æœå°‹æ–°èä¸¦ç›´æ¥å°‡æ¨™é¡Œè½‰æ›ç‚ºå¯é»æ“Šé€£çµ (news_detail)ï¼Œ
    ä¸¦æ›è¡Œè™•ç†è¼¸å‡º HTML
    """
    translated = call_chatgpt(
    "ç¿»è­¯åŠ©æ‰‹",
    f"è«‹å°‡ä»¥ä¸‹ä¸­æ–‡ç¿»è­¯æˆè‹±æ–‡ï¼š\n{user_input}"
    )
    # å–å¾—æ–°èè³‡æ–™ (list)
    news_summary = search_news(
        question=translated,
        start_date=start_date,
        end_date=end_date
    )

    # æŠŠ list è³‡æ–™è½‰ç‚º HTML
    def convert_and_link(news_list):
        text_parts = []
        for item in news_list:
            article_id = item.get("id")
            title = item.get("title", "")
            summary = item.get("summary", "")
            d=item.get("date")
            try:
                url = reverse('news_detail', kwargs={'article_id': article_id})
                title_html = f'<a href="{url}" target="_blank">{title}</a>'
            except:
                title_html = title
            text_parts.append(f"<b>{title_html}</b><br><b>{d}</b><br>{summary}")
        return "<br><br>".join(text_parts)

    news_summary_with_links = convert_and_link(news_summary)
    analysis_prompt = f"""
    ä½ æ˜¯ä¸€ä½å°ˆæ¥­æ–°èåˆ†æå¸«ã€‚è«‹å¹«æˆ‘åˆ†æä»¥ä¸‹æ–°èå…§å®¹ï¼š
    {news_summary}

    è«‹æä¾›ï¼š
    1. æ–°èçš„ä¸»è¦äº‹ä»¶æˆ–ä¸»é¡Œ
    2. æ¯å‰‡æ–°èçš„é‡è¦è³‡è¨Šæ‘˜è¦
    3. å°åŠ å¯†è²¨å¹£å¸‚å ´å¯èƒ½çš„å½±éŸ¿ï¼ˆè‹¥æœ‰ï¼‰
    """

    analyze = call_chatgpt("æ–°èåˆ†æå¸«", analysis_prompt).replace("\n", "<br>")

    return {
        "text": "ğŸ“°â˜…æ–°èæ¨¡å¡Š",
        "extra_data": news_summary_with_links,
        "analyze" : analyze
    }

# ç¶“æ¿Ÿ/å€å¡Šéˆå…¶ä»–æ•¸æ“šæ¨¡çµ„
def run_other_agent(user, user_input, start_date=None, end_date=None):
    if end_date is None:
        end_date = datetime.now().date()

    # FinancialData - æŠ˜ç·šåœ–ç”¨ close_price
    financial_data_sample = []
    symbols = FinancialSymbol.objects.all()[:1]
    for symbol in symbols:
        data_qs = symbol.financial_data.filter(
            date__lte=end_date
        ).order_by('-date')[:7]
        for d in data_qs:
            financial_data_sample.append({
                "symbol": symbol.name,
                "date": d.date.isoformat(),  # ç”¨å­—ä¸²
                "value": d.close_price       # æŠ˜ç·šåœ–ç”¨å€¼
            })

    # IndicatorValue - æŠ˜ç·šåœ–ç”¨ value
    indicator_data_sample = []
    indicators = Indicator.objects.all()[:1]
    for indicator in indicators:
        data_qs = IndicatorValue.objects.filter(
            indicator=indicator,
            date__lte=end_date
        ).order_by('-date')[:7]
        for d in data_qs:
            indicator_data_sample.append({
                "indicator": indicator.name,
                "date": d.date.isoformat(),
                "value": d.value
            })

    # åˆä½µåˆ° extra_dataï¼Œä¿ç•™åˆ†é¡
    extra_data = {
        "financial_data": financial_data_sample,
        "indicator_data": indicator_data_sample,
    }

    # ç”Ÿæˆ prompt
    analysis_prompt = f"""
        ä½ æ˜¯ä¸€ä½å°ˆæ¥­åŠ å¯†è²¨å¹£èˆ‡ç¶“æ¿Ÿåˆ†æå¸«ï¼Œè«‹åˆ©ç”¨ä»¥ä¸‹æ•¸æ“šï¼š
        {extra_data}

        è«‹æä¾›ç°¡çŸ­çµè«–ã€‚ä¸¦æ ¹æ“šä½¿ç”¨è€…å•é¡Œã€Œ{user_input}ã€å›ç­”ï¼Œä½¿åˆ†ææ›´è²¼åˆ‡å…¶éœ€æ±‚ã€‚
        """

    analyze = call_chatgpt("åˆ†æå¸«", analysis_prompt).replace("\n", "<br>")

    return {
        "text": "ğŸ“Šâ˜…å…¶ä»–ç¶“æ¿Ÿæ•¸æ“šæŠ˜ç·šåœ–è³‡æ–™",
        "extra_data": extra_data,
        "analyze": analyze
    }

RISK_QUESTIONNAIRE_IDS = [2, 3, 4, 9]

# å•å·æ¨¡çµ„
def run_survey_agent(user, user_input, start_date=None, end_date=None): 

    if user.is_authenticated:
        # å–å¾—ä½¿ç”¨è€…çš„å•å·é¢¨éšªåˆ†æ
        user_answers = UserAnswer.objects.filter(
            user=user,
        ).prefetch_related("selected_options")
        total_score = 0
        answer_count = 0
        for ans in user_answers:
            for option in ans.selected_options.all():
                q_order = ans.question.questionnaire.id
                if q_order in RISK_QUESTIONNAIRE_IDS:
                    total_score += option.score
                    answer_count += 1

        if answer_count == 0:
            link = reverse('agent:questionnaire_list')
            return {
            "text": f"ğŸ§¾ğŸ“¢â˜…å•å·æ¨¡å¡Š",
            "extra_data": f'<a href="{link}" target="_blank">è«‹å…ˆå¡«å¯«å•å·é é¢(å¡«å•å·ç·¨è™Ÿ2ã€3ã€4ã€9èƒ½æ›´æº–ç¢ºåˆ¤æ–·)</a>',
            "analyze": "ä½¿ç”¨è€…æ²’æœ‰å¡«å¯«å•å·ï¼Œç„¡æ³•åˆ¤æ–·å±¬æ€§"
            }
        else:
            average = total_score / answer_count

            # allocation èˆ‡é¢¨éšªå±¬æ€§åˆ¤æ–·
            ratio = min(max(average / 5, 0), 1)
            allocation = {
                "ç©©å®šå¹£": 0.6 * (1 - ratio),
                "ä¸»æµå¹£": 0.3,
                "æˆé•·å¹£": 0.1 + 0.3 * ratio,
                "è¿·å› å¹£": 0.0 + 0.2 * ratio,
            }
            total = sum(allocation.values())
            allocation = {k: round(v/total, 2) for k, v in allocation.items()}

            if average <= 2.5:
                risk_type = "ä¿å®ˆå‹"
            elif average <= 4:
                risk_type = "ç©©å¥å‹"
            else:
                risk_type = "ç©æ¥µå‹"
            allocation_text = "<br>".join([f"ãƒ»{k}ï¼š{v*100:.0f}%" for k, v in allocation.items()])

            link = reverse('agent:analysis_result_view')

            records_text = (
                f"ğŸ“Š <b>æ‚¨çš„æŠ•è³‡é¢¨éšªå±¬æ€§ï¼š</b><span style='color:blue'>{risk_type}</span><br>"
                f"ğŸ“ˆ <b>å•å·å¹³å‡åˆ†æ•¸ï¼š</b>{average:.2f} åˆ†<br><br>"
                f"ğŸ’¡ <b>å»ºè­°è³‡ç”¢é…ç½®ï¼š</b><br>{allocation_text}<br><br>"
                f'<a href="{link}" target="_blank">æŸ¥çœ‹æ›´å¤š</a>'
            )

        return {
            "text": f"ğŸ§¾ğŸ“¢â˜…å•å·æ¨¡å¡Š",
            "extra_data": records_text,
            "analyze": records_text
        }
    else:
        link = reverse('login')
        return {
            "text": f"ğŸ§¾ğŸ“¢â˜…å•å·æ¨¡å¡Š",
            "extra_data": f'<a href="{link}">è«‹å…ˆç™»å…¥ï¼Œä»¥å–å¾—æ›´æº–ç¢ºçš„åˆ¤æ–·</a>',
            "analyze": "ä½¿ç”¨è€…æ²’æœ‰ç™»å…¥ï¼Œç„¡æ³•åˆ¤æ–·å±¬æ€§"
            }
# -----------5.å„é¡æ™ºèƒ½åˆ†æå°æ¨¡çµ„ï¼ˆåƒ¹æ ¼ã€æ–°èã€å…¶ä»–æ•¸æ“šã€å•å·ï¼‰


def parse_date_range_from_input(user_input):
    """ç”¨ GPT è§£æä½¿ç”¨è€…è¼¸å…¥çš„æ™‚é–“ç¯„åœï¼Œå›å‚³ start_date, end_date"""
    today_str = datetime.today().strftime("%Y-%m-%d")
    prompt = f"""
    ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„è²¡ç¶“åŠ©ç†ï¼š
    ä½¿ç”¨è€…è¼¸å…¥ä»¥ä¸‹å¥å­ï¼Œè«‹åˆ¤æ–·ä»–æƒ³æŸ¥è©¢çš„æ™‚é–“ç¯„åœã€‚
    å¦‚æœèªªã€Œ1Mã€ã€ã€Œæœ¬æœˆã€ã€ã€Œéå»ä¸€å€‹æœˆã€ã€ã€Œ7Dã€ã€ã€Œä»Šå¤©ã€ç­‰ï¼Œè«‹å›å‚³é–‹å§‹èˆ‡çµæŸæ—¥æœŸï¼Œ
    æ ¼å¼ç‚º YYYY-MM-DDï¼Œä»Šå¤©æ˜¯ {today_str}ã€‚
    å¦‚æœæ²’æœ‰æŒ‡å®šæ™‚é–“ï¼Œè«‹å›å‚³ç©ºå€¼ã€‚
    è¼¸å…¥å¥å­ï¼š{user_input}
    è«‹åªç”¨ JSON æ ¼å¼è¼¸å‡ºï¼Œä¾‹å¦‚ï¼š{{"start_date": "2025-07-13", "end_date": "2025-08-13"}}
    """
    result = call_chatgpt("æ™‚é–“è§£æåŠ©ç†", prompt)
    print(user_input, result)
    try:
        data = json.loads(result)

        # æŠŠç©ºå­—ä¸²è½‰æˆ None
        start_date = data.get("start_date") or None
        end_date = data.get("end_date") or None

        return start_date, end_date
    except:
        return None, None
    



# 4. æ™ºèƒ½å°è©±/æ¨¡çµ„åˆ†é¡èˆ‡å¤šæºæ•¸æ“šSSEä¸²æµå›è¦†-----------
@csrf_exempt
@require_http_methods(["GET"])
def classify_question_api(request):
    def event_stream():
        # è®€å–å‚³å…¥è³‡æ–™
        data = json.loads(request.GET.get("payload", "{}"))
        user_input = data.get("user_input", "").strip()
        selected_modules = data.get("selected_modules", [])
        user = request.user
        yield f'data: {json.dumps({"progress": "loding", "result": {"module": "loding","text": "åˆ†æå•é¡Œä¸­", "data": []}}, ensure_ascii=False)}\n\n'
        # 1ï¸âƒ£ åˆ†é¡
        classification_prompt = f"""
        ä½ æ˜¯ä¸€å€‹ç²¾æº–çš„åˆ†é¡å™¨ï¼Œè«‹åˆ¤æ–·ä¸‹åˆ—å¥å­å±¬æ–¼å“ªäº›é¡åˆ¥ï¼š
        - æ–°èï¼ˆnewsï¼‰ï¼šå…§å®¹æ¶‰åŠè¿‘æœŸäº‹ä»¶ã€æ™‚äº‹ã€æ”¿ç­–ã€å…¬å‘Šæˆ–å¸‚å ´å‹•æ…‹ã€‚
        - åŠ å¯†è²¨å¹£åƒ¹æ ¼ï¼ˆpriceï¼‰ï¼šå…§å®¹èˆ‡åŠ å¯†è²¨å¹£ã€ä»£å¹£æˆ–å¸‚å ´åƒ¹æ ¼ã€è¡Œæƒ…ã€è®ŠåŒ–ç›¸é—œã€‚
        - å…¶ä»–ç¶“æ¿Ÿæ•¸æ“šï¼ˆotherï¼‰ï¼šå…§å®¹éœ€è¦æ›´å¤šå¸‚å ´ã€é‡‘èæˆ–ç¶“æ¿Ÿç›¸é—œè³‡æ–™ä½œç‚ºèƒŒæ™¯æˆ–åˆ†æä¾æ“šã€‚
        - å•å·ï¼ˆquestionnaireï¼‰ï¼šä½¿ç”¨è€…è¡¨é”å€‹äººæ„åœ–ã€éœ€æ±‚ã€æŠ•è³‡å»ºè­°æˆ–åå¥½ï¼ˆå¦‚éœ€è¦å¹«å¿™æ¨è–¦ã€åˆ†æã€å»ºè­°ï¼‰ã€‚

        åˆ¤æ–·é‚è¼¯ï¼š
        - åªè¦å¥å­åŒ…å«ã€ŒåŠ å¯†è²¨å¹£ã€ã€ã€Œæ¯”ç‰¹å¹£ã€ç­‰é—œéµå­—ï¼Œæˆ–è€…æåˆ°åŠ å¯†è²¨å¹£åç¨±ï¼Œè«‹å‹™å¿…æ¨™ç¤ºpriceã€‚
        - è‹¥å¥å­æ¶‰åŠè¿‘æœŸäº‹ä»¶ã€æ¶ˆæ¯ã€å¸‚å ´å…¬å‘Šï¼ŒåŒ…å«newsã€‚
        - è‹¥éœ€æŸ¥æ‰¾åŠåˆ†æé¡å¤–è³‡æ–™ï¼ˆéåƒ¹æ ¼æˆ–æ–°èï¼‰ï¼ŒåŒ…å«otherã€‚
        - è¡¨é”å€‹äººéœ€æ±‚ã€æŠ•è³‡å»ºè­°å‰‡åŒ…å«questionnaireã€‚
        - è‹¥çš†ä¸ç¬¦ï¼Œå›å‚³ ()ã€‚

        ç¯„ä¾‹ï¼š
        è¼¸å…¥ï¼šæˆ‘æƒ³æŸ¥æ¯”ç‰¹å¹£åƒ¹æ ¼ â†’ price
        è¼¸å…¥ï¼š9æœˆçš„æ¯”ç‰¹å¹£è¡Œæƒ…æ€éº¼æ¨£ï¼Ÿ â†’ price
        è¼¸å…¥ï¼šè«‹çµ¦æˆ‘å…¶ä»–ç›¸é—œæ•¸æ“š â†’ price, other
        è¼¸å…¥ï¼šæœ€è¿‘æ¯”ç‰¹å¹£æœ‰ä»€éº¼æ¶ˆæ¯ï¼Ÿ â†’ news
        è¼¸å…¥ï¼šæˆ‘æƒ³è¦æŠ•è³‡å»ºè­° â†’ questionnaire
        è¼¸å…¥ï¼šé€™æ˜¯ç„¡é—œå…§å®¹ â†’ ()

        è«‹åªè¼¸å‡ºåˆ†é¡çµæœï¼ˆå¦‚ï¼šnews, priceï¼‰ã€‚

        è¼¸å…¥å¥å­ï¼š{user_input}
        """

        result = call_chatgpt("ä½ æ˜¯ä¸€å€‹ç²¾æº–çš„åˆ†é¡å™¨", classification_prompt)
        classifications = [c.strip().lower() for c in result.split(",") if c.strip()]
        combined = list(set(selected_modules + classifications))

        module_map = {
            "price": run_price_agent,
            "news": run_news_agent,
            "other": run_other_agent,
            "questionnaire": run_survey_agent
        }
        
        ordered_combined = [k for k in module_map.keys() if k in combined]



        # æ¨é€åˆ†é¡çµæœ
        yield f"data: {json.dumps({'classifications': ordered_combined}, ensure_ascii=False)}\n\n"
        final_answers = []
        if ordered_combined:
        # è§£ææ—¥æœŸ
            start_date, end_date = parse_date_range_from_input(user_input)


            # åŸ·è¡Œå„æ¨¡çµ„
            for module_name in ordered_combined:
                if module_name in module_map:
                    # å…ˆæ¨é€ã€Œç”Ÿæˆä¸­ã€è¨Šæ¯
                    yield f'data: {json.dumps({"progress": "loding", "result": {"module": "loding","text": f"{module_name}ç”Ÿæˆä¸­", "data": []}}, ensure_ascii=False)}\n\n'


                    # åŸ·è¡Œ module
                    answer = module_map[module_name](user,user_input, start_date, end_date)

                    # æ•´ç†çµæœ
                    if isinstance(answer, dict):
                        final_answers.append({
                            "module": module_name,
                            "text": answer.get("text", ""),
                            "data": answer.get("extra_data", []),
                            "analyze" : answer.get("analyze", ""),
                        })
                    else:
                        final_answers.append({
                            "module": module_name,
                            "text": str(answer),
                            "analyze" : ""
                        })
                    # æ¯è·‘å®Œä¸€å€‹æ¨¡çµ„å°±æ¨é€çœŸæ­£çµæœ
                    yield f"data: {json.dumps({'progress': module_name, 'result': final_answers[-1]}, ensure_ascii=False)}\n\n"


        if not final_answers:
            final_answers.append({
                "module": "none",
                "text": ("æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•ç†è§£æ‚¨çš„å•é¡Œæˆ–æœªèƒ½è­˜åˆ¥ç›¸é—œæ¨¡çµ„ã€‚"
                        "è«‹ç¢ºèªæ‚¨çš„æå•å…§å®¹æ˜¯å¦å®Œæ•´ï¼Œæˆ–å˜—è©¦é‡æ–°æè¿°æ‚¨çš„éœ€æ±‚ã€‚è¬è¬ï¼<br>"
                        "ä½¿ç”¨èªªæ˜ï¼š<br>"
                        "1. è«‹ç›´æ¥è¼¸å…¥æ‚¨çš„å•é¡Œæˆ–éœ€æ±‚ã€‚<br>"
                        "2. å¯é¸æ“‡é©åˆçš„æ¨¡çµ„ä»¥ç²å¾—æ›´ç²¾æº–çš„å”åŠ©ï¼Œå¦‚æ–°èæŸ¥è©¢ã€åƒ¹æ ¼æŸ¥è©¢ã€ç¶“æ¿Ÿæ•¸æ“šåˆ†æç­‰ã€‚<br>"
                        "3. è‹¥ä¸ç¢ºå®šï¼Œè«‹ç°¡å–®æè¿°æ‚¨çš„å•é¡Œï¼Œæˆ‘å€‘æœƒå˜—è©¦è‡ªå‹•åˆ¤æ–·æ‰€éœ€æ¨¡çµ„ã€‚"),
                "data": []
            })
            yield f"data: {json.dumps({'progress': 'none', 'result': final_answers[-1]}, ensure_ascii=False)}\n\n"

        # 5ï¸âƒ£ æ•´åˆå›è¦†
        yield f'data: {json.dumps({"progress": "loding", "result": {"module": "loding","text": "æ•´åˆå›è¦†ä¸­", "data": []}}, ensure_ascii=False)}\n\n'
        integrated_summary = ""
        try:
            integration_contents = []
            for f in final_answers:
                data_block = f.get('analyze')
                module_name = f.get('module', 'unknown')
                if isinstance(data_block, list):
                    data_str = "\n".join([str(d) for d in data_block])
                else:
                    data_str = str(data_block)
                integration_contents.append(f"[{module_name} æ¨¡å¡Š]\n{data_str}")
            integration_prompt_content = "\n".join(integration_contents)

            integration_prompt = f"""
            ä½¿ç”¨è€…å•é¡Œï¼š{user_input}
            ä»¥ä¸‹æ˜¯å¤šå€‹ä¸åŒä¾†æºçš„æ¨¡å¡Šè¼¸å‡ºï¼Œè«‹å¹«æˆ‘æ•´åˆæˆæ¢åˆ—å¼çš„è‡ªç„¶èªè¨€çš„å›è¦†ï¼Œ
            ä¿ç•™é‡è¦æ•¸æ“šèˆ‡äº‹ä»¶ï¼Œé‚è¼¯æ¸…æ™°ï¼Œé©åˆç›´æ¥å›è¦†ä½¿ç”¨è€…ï¼Œä¸¦åœ¨æœ€å¾Œå›ç­”ä½¿ç”¨è€…çš„å•é¡Œï¼š
            {integration_prompt_content}
            
            """
            integrated_summary = call_chatgpt("ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„è³‡è¨Šæ•´åˆåŠ©ç†", integration_prompt)
        except Exception as e:
            integrated_summary = f"âš ï¸ æ•´åˆå¤±æ•—ï¼š{str(e)}"

        # æœ€å¾Œä¸€æ¬¡æ¨é€ï¼ˆæ•´åˆå›è¦†ï¼‰
        yield f"data: {json.dumps({'integrated_summary': integrated_summary}, ensure_ascii=False)}\n\n"

        DialogEvaluation.objects.create(
            user_input=user_input,
            expected_intent="(äººå·¥)èªç‚ºé€™å¥è©±æ‡‰è©²å±¬æ–¼å“ªç¨®æ„åœ–ï¼ˆæ¨™æº–ç­”æ¡ˆï¼‰",  # ä¹Ÿå¯æ”¹æˆæ›´ç²¾ç¢ºçš„æ„åœ–
            predicted_intent=", ".join(ordered_combined) + (f", {start_date} ~ {end_date}" if start_date and end_date else ""),
            expected_response="(äººå·¥)èªç‚ºåˆé©çš„æ©Ÿå™¨äººå›æ‡‰",
            generated_response=integrated_summary,
            analyze_data=json.dumps([fa.get("analyze", "") for fa in final_answers], ensure_ascii=False),  # é€™ä¸€è¡Œå­˜æ‰€æœ‰ analyze
            task_success=True  # è‹¥æœ‰å¯¦éš›æˆåŠŸåˆ¤æ–·æ¢ä»¶å¯æ›¿æ›
        )
        # å¯ä»¥å†è£œä¸€å€‹å®Œæˆè¨Šè™Ÿ
        yield "event: end\ndata: done\n\n"

    # SSE å›æ‡‰
    response = StreamingHttpResponse(event_stream(), content_type='text/event-stream')
    response['Cache-Control'] = 'no-cache'
    return response
# -----------4. æ™ºèƒ½å°è©±/æ¨¡çµ„åˆ†é¡èˆ‡å¤šæºæ•¸æ“šSSEä¸²æµå›è¦†


def chat_view(request):
    return render(request, "chat2.html")



@csrf_exempt
@require_http_methods(["GET"])
def get_module_suggestions_api(request):
    """
    æ ¹æ“šä½¿ç”¨è€…é¸æ“‡çš„æ¨¡çµ„å›å‚³æ¨è–¦å•é¡Œåˆ—è¡¨
    """
    selected_modules = request.GET.getlist("modules[]", [])

    # å„æ¨¡çµ„å°æ‡‰å»ºè­°
    suggestions = {
        "price": [
            "ç›®å‰æ¯”ç‰¹å¹£åƒ¹æ ¼åˆ†æ",
            "ä»¥å¤ªåŠæŠ€è¡“æŒ‡æ¨™èˆ‡èµ°å‹¢",
            "åŠ å¯†è²¨å¹£å¸‚å ´æ¼²è·ŒåŸå› ",
        ],
        "news": [
            "æœ€è¿‘åŠ å¯†è²¨å¹£æ–°èé‡é»",
            "æ¯”ç‰¹å¹£ç›¸é—œæ”¿ç­–æ›´æ–°",
            "æœ€æ–°å¸‚å ´å…¬å‘Šèˆ‡äº‹ä»¶",
        ],
        "other": [
            "å°è‚¡èˆ‡ç¾è‚¡çš„ç›¸é—œæ€§",
            "ç¾å…ƒæŒ‡æ•¸å°å¸‚å ´çš„å½±éŸ¿",
            "é€šè†¨æ•¸æ“šèˆ‡åŠ å¯†è²¨å¹£é—œä¿‚",
        ],
        "questionnaire": [
            "è«‹æ ¹æ“šå•å·çµæœçµ¦æˆ‘æŠ•è³‡å»ºè­°",
            "å¹«æˆ‘æ¨è–¦é©åˆçš„æŠ•è³‡æ¨™çš„",
            "åˆ†ææˆ‘ç›®å‰çš„æŠ•è³‡åå¥½",
        ]
    }

    # âœ… è‹¥ä½¿ç”¨è€…æ²’æœ‰å‹¾é¸æ¨¡çµ„ â†’ çµ¦ã€Œç¶œåˆå»ºè­°ã€
    if not selected_modules:
        merged_suggestions = [
            "ç›®å‰æ¯”ç‰¹å¹£åƒ¹æ ¼åˆ†æ",
            "çµ¦æˆ‘ä¹æœˆçš„ä¹™å¤ªåŠåƒ¹æ ¼ï¼Œä¸¦çµ¦æˆ‘æ–°èè·Ÿç›¸é—œæ•¸æ“šï¼Œä¸¦çµ¦æˆ‘æŠ•è³‡å»ºè­°",
            "æœ€è¿‘åŠ å¯†è²¨å¹£æ–°èé‡é»",
        ]
    else:
        #æ¸¬è©¦ä½¿ç”¨ï¼Œæœªä¾†å¯ä»¥ä½¿ç”¨è¨»è§£çš„ç‰ˆæœ¬
        merged_suggestions = [ 
            "ç›®å‰æ¯”ç‰¹å¹£åƒ¹æ ¼åˆ†æ",
            "çµ¦æˆ‘ä¹æœˆçš„ä¹™å¤ªåŠåƒ¹æ ¼ï¼Œä¸¦çµ¦æˆ‘æ–°èè·Ÿç›¸é—œæ•¸æ“šï¼Œä¸¦çµ¦æˆ‘æŠ•è³‡å»ºè­°",
            "æœ€è¿‘åŠ å¯†è²¨å¹£æ–°èé‡é»",
        ]
        '''
        # æ•´åˆä½¿ç”¨è€…é¸æ“‡æ¨¡çµ„çš„å»ºè­°
        merged_suggestions = []
        for module in selected_modules:
            merged_suggestions.extend(suggestions.get(module, []))
        '''
    return JsonResponse({"suggestions": merged_suggestions}, json_dumps_params={"ensure_ascii": False})
