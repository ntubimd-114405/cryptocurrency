import os
import json
import re
from collections import Counter
from decimal import Decimal
from datetime import date,datetime,timedelta
import time

import numpy as np
import pandas as pd
import ta
from sklearn.feature_extraction.text import CountVectorizer

from django.utils import timezone
from django.conf import settings
from django.shortcuts import render, get_object_or_404,redirect
from django.http import HttpResponse
from django.contrib.auth.decorators import login_required
from django.utils.timezone import now
from django.db import IntegrityError
from django.db.models import Min, Max, Sum, DateField
from django.db.models.functions import Cast
from django.urls import reverse
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt

from .models import WeeklyReport
from main.models import CoinHistory,Coin,UserProfile, BitcoinPrice
from news.models import Article
from other.models import FinancialData, IndicatorValue, BitcoinMetricData, FinancialSymbol
from agent.models import Questionnaire, Question, AnswerOption, UserAnswer, UserQuestionnaireRecord
from data_analysis.text_generation.chatgpt_api import call_chatgpt
from data_analysis.crypto_ai_agent.news_agent import search_news

from django.http import StreamingHttpResponse, JsonResponse
from django.views.decorators.csrf import csrf_exempt
from django.views.decorators.http import require_http_methods




def load_price_data_from_db(coin_id, start_date=None, end_date=None):
    queryset = CoinHistory.objects.filter(coin_id=coin_id)
    name = Coin.objects.get(id=1).coinname
    if start_date:
        queryset = queryset.filter(date__gte=start_date)
    if end_date:
        queryset = queryset.filter(date__lte=end_date)

    queryset = queryset.order_by('-date').values(
        'date', 'open_price', 'high_price', 'low_price', 'close_price', 'volume'
    )[:60*24*120] #120å¤©

    df = pd.DataFrame.from_records(queryset)
    df.rename(columns={
        'date': 'Date',
        'open_price': 'Open',
        'high_price': 'High',
        'low_price': 'Low',
        'close_price': 'Close',
        'volume': 'Volume',
    }, inplace=True)

    df['Date'] = pd.to_datetime(df['Date'])
    df.set_index('Date', inplace=True)

    daily_df = df.resample('1D').agg({
        'Open': 'first',
        'High': 'max',
        'Low': 'min',
        'Close': 'last',
        'Volume': 'sum'
    }).dropna().reset_index()

    for col in ['Open', 'High', 'Low', 'Close', 'Volume']:
        daily_df[col] = daily_df[col].astype(float)

    return name,daily_df

# å‡è³‡æ–™ç”Ÿæˆå™¨ï¼ˆæ–¹ä¾¿æ¸¬è©¦ï¼‰
def fake_load_price_data_from_db():
    date_range = pd.date_range(end='2025-06-23', periods=90)
    np.random.seed(42)
    close_prices = np.random.uniform(25000, 27000, size=len(date_range)).round(2)
    open_prices = (close_prices + np.random.uniform(-300, 300, size=len(date_range))).round(2)
    high_prices = np.maximum(close_prices, open_prices) + np.random.uniform(0, 200, size=len(date_range)).round(2)
    low_prices = np.minimum(close_prices, open_prices) - np.random.uniform(0, 200, size=len(date_range)).round(2)
    volumes = np.random.uniform(1000, 5000, size=len(date_range)).round()

    df = pd.DataFrame({
        'Date': date_range,
        'Open': open_prices,
        'High': high_prices,
        'Low': low_prices,
        'Close': close_prices,
        'Volume': volumes
    })
    return df

# æŠ€è¡“æŒ‡æ¨™è¨ˆç®—
def add_technical_indicators(df):
    # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
    df['rsi'] = ta.momentum.RSIIndicator(df['Close'], window=14).rsi()
    macd = ta.trend.MACD(df['Close'])
    df['macd'] = macd.macd()
    df['macd_signal'] = macd.macd_signal()
    df['ma20'] = df['Close'].rolling(window=20).mean()
    df['ma60'] = df['Close'].rolling(window=60).mean()

    # å°‡æ—¥æœŸè½‰ç‚ºå­—ä¸²æ ¼å¼ä¾›å‰ç«¯ä½¿ç”¨
    df['Date_str'] = df['Date'].dt.strftime('%Y-%m-%d')

    # å»ºç«‹ç•« K ç·šåœ–ç”¨æ¬„ä½æ ¼å¼ï¼ˆè‹¥ä½ ä½¿ç”¨ plotly æˆ– Highcharts ç­‰ï¼‰
    df['ohlc'] = df.apply(lambda row: {
        'x': row['Date_str'],
        'open': row['Open'],
        'high': row['High'],
        'low': row['Low'],
        'close': row['Close']
    }, axis=1)

    # RSI for æŠ˜ç·šåœ–
    df['rsi_point'] = df.apply(lambda row: {
        'x': row['Date_str'],
        'y': row['rsi']
    }, axis=1)

    # MACD + Signal Line
    df['macd_bar'] = df.apply(lambda row: {
        'x': row['Date_str'],
        'y': row['macd']
    }, axis=1)
    df['macd_signal_line'] = df.apply(lambda row: {
        'x': row['Date_str'],
        'y': row['macd_signal']
    }, axis=1)

    return df

def get_recent_articles(start, end):
    # å‡è¨­ start å’Œ end æ˜¯ datetime.date æˆ– datetime.datetime ç‰©ä»¶
    # å¦‚æœæ˜¯æ—¥æœŸï¼Œè½‰æˆ timezone-aware datetime çš„å€é–“
    if isinstance(start, (date,)):
        start = timezone.make_aware(datetime.combine(start, datetime.min.time()))
    if isinstance(end, (date,)):
        end = timezone.make_aware(datetime.combine(end, datetime.max.time()))

    articles = Article.objects.filter(time__gte=start, time__lte=end).order_by('-time')
    return articles


def process_word_frequency_sklearn(news_texts, top_n=30, max_features=1000):
    stop_words = [
        'the', 'in', 'to', 'and', 'of', 'on', 'for', 'with', 'at', 'by', 'a', 'an',
        'is', 'are', 'was', 'were', 'has', 'have', 'it', 'this', 'that', 'as', 'but', 'or', 'if',
        's', 'u', 'k'  # é¡å¤–å™ªéŸ³éæ¿¾
    ]
    if isinstance(news_texts, str):
        news_texts = [news_texts]
    vectorizer = CountVectorizer(
        stop_words=stop_words,   # å¯æ”¾é è¨­çš„ 'english' æˆ–è‡ªè¨‚åœç”¨è©åˆ—è¡¨
        max_features=max_features
        )
    word_count_matrix = vectorizer.fit_transform(news_texts)
    feature_names = vectorizer.get_feature_names_out()

    # åˆè¨ˆæ‰€æœ‰æ–‡ç« çš„è©é »
    total_counts = word_count_matrix.sum(axis=0).A1

    # æ’åºï¼Œå–å‰ top_n
    sorted_indices = total_counts.argsort()[::-1][:top_n]
    keywords = [(feature_names[i], total_counts[i]) for i in sorted_indices]
    results = [(word, int(freq)) for word, freq in keywords]
    return results



# Decimal è½‰ float

def decimal_to_float(data_list):
    return [float(val) if isinstance(val, Decimal) else val for val in data_list]

# ä¸»è¦–åœ–ï¼šweekly report
def full_month_data_view():
    today = timezone.now().date()
    start_date = today - timedelta(days=120)

    # ğŸ“ˆ FinancialData è³‡æ–™
    financial_qs = FinancialData.objects.select_related('symbol').filter(date__range=(start_date, today))
    financial_df = pd.DataFrame(list(financial_qs.values(
        'symbol__symbol', 'symbol__name', 'date',
        'open_price', 'high_price', 'low_price', 'close_price', 'volume'
    )))

    # ğŸ§  IndicatorValue è³‡æ–™
    indicator_qs = IndicatorValue.objects.select_related('indicator').filter(date__range=(start_date, today))
    indicator_df = pd.DataFrame(list(indicator_qs.values(
        'indicator__name', 'indicator__abbreviation', 'date', 'value'
    )))

    # ğŸ”— BitcoinMetricData è³‡æ–™
    bitcoin_qs = BitcoinMetricData.objects.select_related('metric').filter(date__range=(start_date, today))
    bitcoin_df = pd.DataFrame(list(bitcoin_qs.values(
        'metric__name', 'metric__unit', 'metric__period', 'date', 'value'
    )))

    # ğŸ“Š è½‰ç‚º JSON å‚³åˆ°æ¨¡æ¿ï¼ˆæˆ–å¯ä»¥ä¹‹å¾Œè½‰ç‚º REST APIï¼‰
    return {
        'financial_data_json': financial_df.to_json(orient='records', date_format='iso'),
        'indicator_data_json': indicator_df.to_json(orient='records', date_format='iso'),
        'bitcoin_data_json': bitcoin_df.to_json(orient='records', date_format='iso'),
    }



@login_required
def report_list(request):
    user = request.user
    reports = WeeklyReport.objects.filter(user=user).order_by('-year', '-week')

    today = now().date()
    this_year, this_week, _ = today.isocalendar()

    # å¹´ä»½ç¯„åœï¼š2022åˆ°ä»Šå¹´
    year_list = list(range(2022, this_year + 1))

    # å»ºç«‹ä¸€å€‹ dictï¼Œkey: å¹´ï¼Œvalue: è©²å¹´å¯é¸é€±æ•¸åˆ—è¡¨
    weeks_by_year = {}
    for year in year_list:
        if year == this_year:
            weeks_by_year[year] = list(range(1, this_week + 1))  # ä»Šå¹´é™å®šåˆ°æœ¬é€±
        else:
            weeks_by_year[year] = list(range(1, 54))  # å…¶ä»–å¹´ä»½å…¨é€±

    context = {
        'reports': reports,
        'year_list': year_list,
        'weeks_by_year': weeks_by_year,
        'this_year': this_year,
        'this_week': this_week,
    }

    return render(request, 'weekly_report_list.html', context)



def convert_id_and_newline(text: str) -> str:
    # é è™•ç†å…¨å½¢ç¬¦è™Ÿèˆ‡å¤§å°å¯«çµ±ä¸€
    text = text.replace('ï¼ˆ', '(').replace('ï¼‰', ')').replace('ï¼š', ':')
    
    # å®šç¾©æ­£å‰‡ï¼Œæ”¯æ´ï¼š
    # - (id:123)ã€(ID:123)
    # - id:123ã€ID:123
    # - å‰é¢å¯æœ‰å¯ç„¡æ‹¬è™Ÿ
    # - ä¸å€åˆ†å¤§å°å¯«
    pattern = r"[\(]?id:(\d+)[\)]?"  # å…ˆåšç°¡å–®åŒ¹é…ï¼Œå†åšè£œå¼·
    regex = re.compile(pattern, flags=re.IGNORECASE)

    def replace_func(match):
        article_id = match.group(1)
        try:
            url = reverse('news_detail', kwargs={'article_id': article_id})
            return f'<a href="{url}">(id:{article_id})</a>'
        except:
            return f"(id:{article_id})"

    # æ›¿æ›æˆé€£çµ
    replaced_text = regex.sub(replace_func, text)
    # æ›è¡Œè™•ç†
    replaced_text = replaced_text.replace('\n', '<br>')

    return replaced_text


@login_required
def generate_weekly_report(request):
    user = request.user
    today = now().date()
    year = int(request.POST.get("year", today.isocalendar()[0]))
    week = int(request.POST.get("week", today.isocalendar()[1]))
    print(year,week)
    # âœ… æ ¹æ“š year å’Œ week è¨ˆç®—å‡º start_dateï¼ˆé€±ä¸€ï¼‰èˆ‡ end_dateï¼ˆé€±æ—¥ï¼‰
    start_date = date.fromisocalendar(year, week, 1)
    end_date = start_date + timedelta(days=6)

    # é‡æ–°è¨ˆç®—è³‡æ–™
    coin,df = load_price_data_from_db(1)  # æˆ– user.idï¼Œè¦–ä½ çš„é‚è¼¯
    df = add_technical_indicators(df).tail(30)

    ma20_data = decimal_to_float(df['ma20'].tolist())
    ma60_data = decimal_to_float(df['ma60'].tolist())
    
    news_summary = search_news("BTC") #ç›®å‰å¯«æ­»
    news_summary_with_links = convert_id_and_newline(news_summary)

    news_text = "\n".join([
        " ".join(filter(None, [
            article.title or "",
            article.summary or "",
            article.content or ""
        ]))
        for article in get_recent_articles(start_date, end_date)
    ])

    word_freqs = process_word_frequency_sklearn(news_text)
    print(call_chatgpt(
        system="ä½ æ˜¯ä¸€ä½å°ˆæ¥­é‡‘èåˆ†æå¸«",
        text=f"""å¹«æˆ‘åˆ†æä»¥ä¸‹è©é »å…§å®¹
        {word_freqs}
        """
    ))
    data = {
        "MA20": list(ma20_data[-7:]),
        "MA60": list(ma60_data[-7:]),
        "RSI": df['rsi_point'].dropna().tail(7).tolist(),
        "MACD": df['macd_bar'].dropna().tail(7).tolist(),
        "MACD_Signal": df['macd_signal_line'].dropna().tail(7).tolist(),
        "OHLC": df['ohlc'].dropna().tail(7).tolist(),
    }
    formatted = json.dumps(data, ensure_ascii=False)

    coin_analysis = call_chatgpt(
        system="ä½ æ˜¯ä¸€ä½å°ˆæ¥­é‡‘èåˆ†æå¸«ï¼Œè«‹ç”¨ HTML <div> åŒ…è£ä½ çš„æŠ€è¡“åˆ†æè©•è«–ã€‚",
        text=f"""è«‹ä¾æ“šä»¥ä¸‹åŠ å¯†è²¨å¹£ {coin} çš„æŠ€è¡“åˆ†æè³‡æ–™é€²è¡Œç°¡æ½”è©•è«–ï¼Œæè¿°ç›®å‰å¸‚å ´è¶¨å‹¢èˆ‡å¯èƒ½çš„è®ŠåŒ–ï¼Œé¿å…é€ç­†èªªæ˜ï¼Œåªéœ€ç¸½é«”åˆ†æèˆ‡è§£é‡‹ã€‚è«‹è¼¸å‡ºç‚ºä¸€æ®µ HTML <div>...</div>ï¼Œä¸è¦é¡å¤–æ–‡å­—ï¼š
        {formatted}
        """
    ).strip("```").strip("html")

    summary = call_chatgpt(
        system="ä½ æ˜¯ä¸€ä½æ“…é•·æ’°å¯«è²¡ç¶“ç¸½çµçš„åˆ†æå¸«ã€‚",
        text=f"""
        è«‹ä½ ä»¥å°ˆæ¥­é‡‘èåˆ†æå¸«å£å»ï¼Œç¶œåˆä»¥ä¸‹å…©éƒ¨åˆ†å…§å®¹ï¼Œæ’°å¯«ä¸€æ®µä¸­æ–‡å¸‚å ´ç¸½çµã€‚  
        è«‹å…ˆç”¨æ®µè½ç°¡çŸ­ä»‹ç´¹å¸‚å ´ç‹€æ³ï¼Œ  
        æ¥è‘—ç”¨ HTML çš„ <table> å…ƒç´ ï¼Œå»ºç«‹ä¸€å€‹å…©æ¬„çš„è¡¨æ ¼ï¼Œ  
        å·¦æ¬„æ¨™é¡Œç‚ºã€Œåˆ©å¤šå› ç´ ã€ï¼Œå³æ¬„æ¨™é¡Œç‚ºã€Œåˆ©ç©ºå› ç´ ã€ï¼Œ  
        æ•´æ®µå…§å®¹ç”¨ <div> åŒ…èµ·ä¾†ï¼Œä¸”ä¸è¦é¡å¤–æ–‡å­—ã€‚

        1. æŠ€è¡“åˆ†æè©•è«–ï¼š
        {coin_analysis}

        2. è¿‘æœŸæ–°èæ‘˜è¦ï¼š
        {news_summary}
        """
    ).strip("```").strip("html").strip()

    # ğŸ“Š ä¸­é•·æœŸè§€é»è³‡æ–™æ•´åˆ
    monthly_data = full_month_data_view()
    financial_json = monthly_data['financial_data_json']
    indicator_json = monthly_data['indicator_data_json']
    bitcoin_json = monthly_data['bitcoin_data_json']

    long_term_analysis = call_chatgpt(
        system="ä½ æ˜¯ä¸€ä½é‡‘èå¸‚å ´ç ”ç©¶å“¡ï¼Œè«‹æ’°å¯«ä¸­é•·æœŸè§€å¯Ÿèˆ‡è¶¨å‹¢é æ¸¬ã€‚",
        text=f"""
        è«‹ä½ ä»¥é‡‘èåˆ†æå¸«èº«ä»½ï¼Œæ ¹æ“šä»¥ä¸‹ä¸‰é¡è³‡æ–™ï¼Œæ’°å¯«ä¸€æ®µç´”æ–‡å­—æ ¼å¼çš„ä¸­é•·æœŸå¸‚å ´è§€å¯Ÿèˆ‡è¶¨å‹¢é æ¸¬åˆ†æã€‚
        è«‹é¿å…é€ç­†åˆ—èˆ‰è³‡æ–™ï¼Œåƒ…éœ€å¾ç¸½é«”å±¤é¢åšå‡ºè§£é‡‹èˆ‡é æ¸¬ï¼Œèªæ°£è«‹ä¿æŒå®¢è§€ã€å°ˆæ¥­ï¼Œé¿å…ä½¿ç”¨éå¤šä¸ç¢ºå®šè©ã€‚
        è«‹ç›´æ¥è¼¸å‡ºæ–‡å­—ï¼Œä¸è¦ä½¿ç”¨ HTML æ ¼å¼èˆ‡é¡å¤–æ¨™è¨˜ã€‚
        è³‡æ–™å¦‚ä¸‹ï¼š
        1. é‡‘èåƒ¹æ ¼è³‡æ–™ï¼ˆfinancial_data_jsonï¼‰ï¼š
        {financial_json[:100]}

        2. æŠ€è¡“æŒ‡æ¨™è³‡æ–™ï¼ˆindicator_data_jsonï¼‰ï¼š
        {indicator_json[:100]}

        3. æ¯”ç‰¹å¹£éˆä¸ŠæŒ‡æ¨™è³‡æ–™ï¼ˆbitcoin_data_jsonï¼‰ï¼š
        {bitcoin_json[:100]}
        """
    ).strip("```").strip("html").strip()

    # æ›´æ–°æˆ–æ–°å¢æœ¬é€±å ±å‘Š
    WeeklyReport.objects.update_or_create(
        user=user,
        year=year,
        week=week,
        defaults={
            'start_date': start_date,
            'end_date': end_date,
            'summary': summary,
            'news_summary': news_summary_with_links,
            'word_frequencies': word_freqs,
            'ma20_data': ma20_data,
            'ma60_data': ma60_data,
            'ohlc_data': df['ohlc'].tolist(),
            'rsi_data': df['rsi_point'].dropna().tolist(),
            'macd_data': df['macd_bar'].dropna().tolist(),
            'macd_signal_data': df['macd_signal_line'].dropna().tolist(),
            'coin_analysis':coin_analysis,
            'financial_data_json': financial_json,
            'indicator_data_json': indicator_json,
            'bitcoin_data_json': bitcoin_json,
            'long_term_analysis': long_term_analysis,
        }
    )

    return redirect('weekly_report_list')  # é‡æ–°å°å‘ä½ çš„é€±å ±é 





def my_favorite_coins_view(request):
    # å–å¾—ä½¿ç”¨è€…æœ€æ„›å¹£ç¨®åŠå…¶æœ€æ–°åƒ¹æ ¼
    favorite_coins = request.user.profile.favorite_coin.all()
    latest_prices = {}
    for coin in favorite_coins:
        price_obj = BitcoinPrice.objects.filter(coin=coin).order_by('-timestamp').first()
        if price_obj:
            latest_prices[coin.id] = price_obj

    watchlist = []
    for coin in favorite_coins:
        price = latest_prices.get(coin.id)
        if price:
            watchlist.append({
                'name': coin.coinname,
                'symbol': coin.abbreviation,
                'price': f"{price.usd:,.2f}",
                'change_24h': float(price.change_24h or 0),
                'market_cap': f"{price.market_cap:,.0f}" if price.market_cap else 'N/A',
            })
        else:
            watchlist.append({
                'name': coin.coinname,
                'symbol': coin.abbreviation,
                'price': 'N/A',
                'change_24h': 0,
                'market_cap': 'N/A',
            })
    return watchlist

@login_required
def view_weekly_report_by_id(request, report_id):
    report = get_object_or_404(WeeklyReport, id=report_id, user=request.user)

    context = {
        'summary': report.summary,
        'news_summary': report.news_summary,
        'word_freqs_json': json.dumps(report.word_frequencies),
        'ma20_data': json.dumps(report.ma20_data),
        'ma60_data': json.dumps(report.ma60_data),
        'ohlc_json': json.dumps(report.ohlc_data),
        'rsi_json': json.dumps(report.rsi_data),
        'macd_json': json.dumps(report.macd_data),
        'macd_signal_json': json.dumps(report.macd_signal_data),
        'coin_analysis':report.coin_analysis,
        'financial_data_json': report.financial_data_json,
        'indicator_data_json': report.indicator_data_json,
        'bitcoin_data_json': report.bitcoin_data_json,
        'long_term_analysis': report.long_term_analysis,
        'user': report.user,
        'year': report.year,
        'week': report.week,
        'start_date': report.start_date,
        'end_date': report.end_date,
        'created_at': report.created_at,
        'watchlist': my_favorite_coins_view(request),  # <-- åŠ å…¥é€™è¡Œ
    }

    # ä¹Ÿå¯ä»¥æŠŠå…±ç”¨çš„ full_month_data åŠ é€² contextï¼Œå¦‚æœéœ€è¦
    context.update(full_month_data_view())

    return render(request, 'weekly_report.html', context)


def parse_coin_from_input(user_input):
    """
    ç”¨ GPT è§£æä½¿ç”¨è€…è¼¸å…¥çš„å¹£ç¨®ã€‚
    å¦‚æœæ²’æœ‰æåˆ°ï¼Œé è¨­å›å‚³ 'BTC'ã€‚
    """
    prompt = f"""
    ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„åŠ å¯†è²¨å¹£åŠ©ç†ã€‚
    ä½¿ç”¨è€…æœƒè¼¸å…¥ä¸€å¥è©±ï¼Œå¯èƒ½æœƒæåˆ°æƒ³æŸ¥çš„å¹£ç¨®ï¼Œä¾‹å¦‚ã€Œæ¯”ç‰¹å¹£ã€BTCã€bitcoinã€ä»¥å¤ªåŠã€ETHã€solanaã€ç­‰ã€‚
    å¦‚æœæœ‰æåˆ°å¹£ç¨®ï¼Œè«‹å›å‚³å°æ‡‰çš„å¸¸ç”¨ä»£è™Ÿï¼ˆsymbolï¼‰ï¼Œä¾‹å¦‚ï¼š
    - æ¯”ç‰¹å¹£ â†’ BTC
    - ä»¥å¤ªåŠ â†’ ETH
    - ç‹—ç‹—å¹£ â†’ DOGE
    - Solana â†’ SOL
    - å…¶ä»–å°±å›å‚³æœ€å¸¸è¦‹çš„äº¤æ˜“æ‰€ä»£è™Ÿ
    
    å¦‚æœæ²’æœ‰æåˆ°ä»»ä½•å¹£ç¨®ï¼Œè«‹å›å‚³ "BTC"ã€‚
    
    ä½¿ç”¨è€…è¼¸å…¥ï¼š{user_input}
    
    è«‹åªè¼¸å‡ºä»£è™Ÿï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
    """

    result = call_chatgpt("ä½ æ˜¯ä¸€å€‹å¹£ç¨®è§£æåŠ©ç†", prompt)
    coin_symbol = result.strip().upper()
    return coin_symbol if coin_symbol else "BTC"



def run_news_agent(user_input, start_date=None, end_date=None):
    time.sleep(10)
    return {
        "text": "ğŸ“°â˜…æ–°èæ¨¡å¡Š",
        "extra_data": "æ¸¬è©¦è³‡æ–™"
    }
    """
    æœå°‹æ–°èä¸¦ç›´æ¥å°‡æ¨™é¡Œè½‰æ›ç‚ºå¯é»æ“Šé€£çµ (news_detail)ï¼Œ
    ä¸¦æ›è¡Œè™•ç†è¼¸å‡º HTML
    """

    # å–å¾—æ–°èè³‡æ–™ (list)
    news_summary = search_news(
        question=user_input,
        start_date=start_date,
        end_date=end_date
    )

    # æŠŠ list è³‡æ–™è½‰ç‚º HTML
    def convert_and_link(news_list):
        text_parts = []
        for item in news_list:
            article_id = item.get("id")
            title = item.get("title", "")
            summary = item.get("summary", "")
            try:
                url = reverse('news_detail', kwargs={'article_id': article_id})
                title_html = f'<a href="{url}" target="_blank">{title}</a>'
            except:
                title_html = title
            text_parts.append(f"<b>{title_html}</b><br>{summary}")
        return "<br><br>".join(text_parts)

    news_summary_with_links = convert_and_link(news_summary)

    return {
        "text": "ğŸ“°â˜…æ–°èæ¨¡å¡Š",
        "extra_data": news_summary_with_links
    }




def parse_safe_date(date_str):
    """å°‡å­—ä¸²è½‰æˆ dateï¼Œå¤±æ•—å›å‚³ None"""
    if not date_str:
        return None
    try:
        return datetime.strptime(date_str, "%Y-%m-%d").date()
    except Exception:
        return None

def run_price_agent(user_input, start_date=None, end_date=None):
    coin_symbol = parse_coin_from_input(user_input)
    # ç¢ºèªå¹£ç¨®å­˜åœ¨
    if not Coin.objects.filter(abbreviation=coin_symbol).exists():
        return {"text": f"âš ï¸ æŠ±æ­‰ï¼Œç³»çµ±å…§æ²’æœ‰æ‰¾åˆ° {coin_symbol} çš„è³‡æ–™ã€‚", "extra_data": []}

    qs = CoinHistory.objects.filter(coin__abbreviation=coin_symbol)
    if not qs.exists():
        return {"text": f"âš ï¸ æ¨¡çµ„ price åŸ·è¡Œå¤±æ•—ï¼š{coin_symbol} æš«ç„¡è³‡æ–™", "extra_data": []}

    # å®‰å…¨è½‰æ›å‚³å…¥æ—¥æœŸ
    if start_date:
        start_date = parse_safe_date(str(start_date))
    if end_date:
        end_date = parse_safe_date(str(end_date))

    # å¦‚æœæ²’å‚³æ—¥æœŸæˆ–è§£æå¤±æ•— â†’ ç”¨è³‡æ–™åº«æœ€æ–° 7 å¤©æœ‰è³‡æ–™çš„æ—¥æœŸ
    if start_date is None or end_date is None:
        latest_days = (
            qs.annotate(day=Cast("date", output_field=DateField()))
            .values("day")
            .distinct()
            .order_by("-day")[:7]
        )
        latest_days = sorted([d["day"] for d in latest_days])
        if not latest_days:
            return {"text": f"âš ï¸ æ¨¡çµ„ price åŸ·è¡Œå¤±æ•—ï¼š{coin_symbol} æš«ç„¡è³‡æ–™", "extra_data": []}
        start_date = latest_days[0]
        end_date = latest_days[-1]

    # èšåˆæŸ¥è©¢
    queryset = qs.annotate(day=Cast("date", output_field=DateField())) \
             .filter(day__gte=start_date, day__lte=end_date)
    daily_range = (
        queryset.annotate(day=Cast("date", output_field=DateField()))
        .values("day", "coin__coinname")
        .annotate(
            first_time=Min("date"),
            last_time=Max("date"),
            high_price=Max("high_price"),
            low_price=Min("low_price"),
            volume=Sum("volume"),
        )
        .order_by("day")
    )
    results = []
    for d in daily_range:
        first_record = qs.filter(date=d["first_time"]).first()
        last_record = qs.filter(date=d["last_time"]).first()
        results.append({
            "day": d["day"].strftime("%Y-%m-%d"),
            "coin": d["coin__coinname"],
            "open": float(first_record.open_price) if first_record else None,
            "high": float(d["high_price"]),
            "low": float(d["low_price"]),
            "close": float(last_record.close_price) if last_record else None,
            "volume": float(d["volume"]),
        })

    if not results:
        return {"text": f"âš ï¸ æ¨¡çµ„ price åŸ·è¡Œå¤±æ•—ï¼š{coin_symbol} åœ¨ {start_date} è‡³ {end_date} ä¹‹é–“æ²’æœ‰è³‡æ–™", "extra_data": []}



    return {"text": f"ğŸ’°â˜…åƒ¹æ ¼æ¨¡å¡Š", "extra_data": results}





'''
def run_other_agent(user_input, start_date=None, end_date=None):
    time.sleep(3)
    return {"text": f"ğŸ“Šâ˜…å…¶ä»–ç¶“æ¿Ÿæ•¸æ“šæ¨¡å¡Š,æ¸¬è©¦ä½¿ç”¨", "extra_data": "12345"}
    financial_data = FinancialData.objects.select_related("symbol").order_by("-date")
    indicator_values = IndicatorValue.objects.select_related("indicator").order_by("-date")
    btc_metrics = BitcoinMetricData.objects.select_related("metric").order_by("-date")

    if start_date:
        financial_data = financial_data.filter(date__gte=start_date)
        indicator_values = indicator_values.filter(date__gte=start_date)
        btc_metrics = btc_metrics.filter(date__gte=start_date)
    if end_date:
        financial_data = financial_data.filter(date__lte=end_date)
        indicator_values = indicator_values.filter(date__lte=end_date)
        btc_metrics = btc_metrics.filter(date__lte=end_date)

    lines = ["ğŸ“Šâ˜…å…¶ä»–ç¶“æ¿Ÿæ•¸æ“šæ¨¡å¡Š"]
    lines.append("[FinancialData]")
    lines.extend([f"{x.symbol.symbol} ({x.symbol.name}): é–‹={x.open_price}, é«˜={x.high_price}, ä½={x.low_price}, æ”¶={x.close_price}, é‡={x.volume}ï¼ˆ{x.date}ï¼‰" for x in financial_data[:10]])
    lines.append("[IndicatorValue]")
    lines.extend([f"{x.indicator.name}: {x.value}ï¼ˆ{x.date}ï¼‰" for x in indicator_values[:10]])
    lines.append("[BitcoinMetricData]")
    lines.extend([f"{x.metric.name}: {x.value}ï¼ˆ{x.date}ï¼‰" for x in btc_metrics[:10]])
    return "\n".join(lines)


def run_survey_agent(user_input, start_date=None, end_date=None, record_ids=None):
    queryset = UserQuestionnaireRecord.objects.select_related("user", "questionnaire").order_by("-completed_at")
    #record_ids=[1,2,5]
    # å¦‚æœæŒ‡å®šå¤šå€‹ IDï¼Œç›´æ¥éæ¿¾
    if record_ids:
        queryset = queryset.filter(id__in=record_ids)
    else:
        if start_date:
            queryset = queryset.filter(completed_at__date__gte=start_date)
        if end_date:
            queryset = queryset.filter(completed_at__date__lte=end_date)
        queryset = queryset[:5]  # åªå–æœ€æ–° 5 ç­†

    latest_records = list(queryset)

    if not latest_records:
        return {
            "text": "ğŸ§¾ğŸ“¢â˜…å•å·æ¨¡å¡Š\nç›®å‰æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å•å·ç´€éŒ„",
            "extra_data": []
        }

    # æ•´ç†è¼¸å‡ºæ–‡å­—
    records_text = "\n".join(
        f"{r.user.username} - å•å·: {r.questionnaire.title}ï¼ˆå®Œæˆæ–¼ {r.completed_at.strftime('%Y-%m-%d %H:%M')}ï¼‰"
        for r in latest_records
    )

    # æ•´ç†é¡å¤–è³‡æ–™
    extra_data = [
        {
            "id": r.id,
            "user": r.user.username,
            "questionnaire": r.questionnaire.title,
            "completed_at": r.completed_at.isoformat()
        }
        for r in latest_records
    ]
    return {
        "text": f"ğŸ§¾ğŸ“¢â˜…å•å·æ¨¡å¡Š\n{records_text}",
        "extra_data": extra_data
    }
    '''
def run_other_agent(user_input, start_date=None, end_date=None):

    symbol_name="GC=F"
    try:
        # åªæŠ“æŒ‡å®š symbol
        symbol = FinancialSymbol.objects.get(symbol=symbol_name)
        financial_data = FinancialData.objects.filter(symbol=symbol).order_by('-date')[:10]
    except FinancialSymbol.DoesNotExist:
        return {
            "text": f"ğŸ“Šâ˜…é‡‘èæ•¸æ“šæ¨¡å¡Š\næ‰¾ä¸åˆ° symbol: {symbol_name}",
            "extra_data": []
        }

    # çµ„æ–‡å­—è¼¸å‡º
    lines = [f"ğŸ“Šâ˜…é‡‘èæ•¸æ“šæ¨¡å¡Šï¼ˆ{symbol.symbol} - {symbol.name}ï¼‰"]
    for x in financial_data:
        lines.append(
            f"{x.symbol.symbol} ({x.symbol.name}): "
            f"é–‹={x.open_price}, é«˜={x.high_price}, ä½={x.low_price}, æ”¶={x.close_price}, "
            f"é‡={x.volume}ï¼ˆ{x.date}ï¼‰"
        )

    # å›å‚³å­—å…¸
    return {
        "text": f"ğŸ“Šâ˜…é‡‘èæ•¸æ“šæ¨¡å¡Š",
        "extra_data": [
            {
                "id": x.id,
                "symbol": x.symbol.symbol,
                "name": x.symbol.name,
                "date": x.date.isoformat(),
                "open": x.open_price,
                "high": x.high_price,
                "low": x.low_price,
                "close": x.close_price,
                "volume": x.volume
            } for x in financial_data
        ]
    }


def run_survey_agent(user_input, start_date=None, end_date=None): #Fake
    # æ¨¡æ“¬å•å·è³‡æ–™ï¼Œå…¨éƒ¨ç‚º user123
    latest_records = [
        {
            "id": 101,
            "user": "user123",
            "questionnaire": "æŠ•è³‡ç¶“é©—",
            "completed_at": "2025-09-03T06:53:00",
            "analysis": "ä½¿ç”¨è€…åœ¨éå»æœ‰å¤šå¹´çš„æŠ•è³‡ç¶“é©—ï¼Œå°åŠ å¯†è²¨å¹£å¸‚å ´æ³¢å‹•æœ‰åŸºæœ¬èªçŸ¥ï¼Œåå¥½ä¸­ä½é¢¨éšªç­–ç•¥ã€‚"
        },
        {
            "id": 102,
            "user": "user123",
            "questionnaire": "åŸºæœ¬è³‡æ–™",
            "completed_at": "2025-09-03T06:39:00",
            "analysis": "å¡«å¯«çš„åŸºæœ¬è³‡æ–™å®Œæ•´ï¼Œé¡¯ç¤ºä½¿ç”¨è€…å°å¹³å°æ“ä½œç†Ÿæ‚‰ä¸”å…·å‚™è²¡å‹™ç›¸é—œèƒŒæ™¯ï¼Œå¾ŒçºŒå¯åšå€‹äººåŒ–æ¨è–¦ã€‚"
        },
        {
            "id": 103,
            "user": "user123",
            "questionnaire": "åˆè¦èˆ‡å®‰å…¨",
            "completed_at": "2025-07-07T09:51:00",
            "analysis": "ä½¿ç”¨è€…å°åˆè¦èˆ‡å®‰å…¨è¦ç¯„æœ‰ä¸€å®šç†è§£ï¼Œé¡¯ç¤ºå…¶åœ¨äº¤æ˜“æ™‚æœƒé‡è¦–é¢¨éšªç®¡ç†èˆ‡è³‡é‡‘å®‰å…¨ã€‚"
        },
        {
            "id": 104,
            "user": "user123",
            "questionnaire": "äº¤æ˜“ç­–ç•¥èˆ‡å¿ƒç†è¡Œç‚º",
            "completed_at": "2025-07-07T09:51:00",
            "analysis": "å¡«ç­”é¡¯ç¤ºä½¿ç”¨è€…åå‘ç†æ€§åˆ†æå‹ï¼Œé¢å°å¸‚å ´æ³¢å‹•æ™‚è¼ƒä¸å—æƒ…ç·’å½±éŸ¿ï¼Œé©åˆé•·æœŸç­–ç•¥é…ç½®ã€‚"
        },
        {
            "id": 105,
            "user": "user123",
            "questionnaire": "æœªä¾†çœ‹æ³•èˆ‡é æœŸ",
            "completed_at": "2025-07-07T09:51:00",
            "analysis": "ä½¿ç”¨è€…å°æœªä¾†å¸‚å ´æŠ±æŒç©©å¥æ¨‚è§€æ…‹åº¦ï¼Œé¡˜æ„æ¥å—æ–°å‹åŠ å¯†è³‡ç”¢çš„æŠ•è³‡ï¼Œå»ºè­°æä¾›å¤šæ¨£åŒ–æŠ•è³‡çµ„åˆåƒè€ƒã€‚"
        }
    ]

    # æ¨¡æ“¬ Agent è¼¸å‡ºæ–‡å­—
    text_lines = []

    for r in latest_records:
        text_lines.append(
            f"ğŸ‘¤ ä½¿ç”¨è€…: {r['user']}<br>"
            f"ğŸ“„ å•å·åç¨±: {r['questionnaire']}<br>"
            f"â° å®Œæˆæ™‚é–“: {r['completed_at']}<br>"
            f"ğŸ’¡ æ™ºèƒ½åˆ†æ: {r['analysis']}<br>"
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
        )
    records_text = "<br>".join(text_lines)
    print(records_text,latest_records)
    return {
        "text": f"ğŸ§¾ğŸ“¢â˜…å•å·æ¨¡å¡Š",
        "extra_data": records_text
    }


def parse_date_range_from_input(user_input):
    """ç”¨ GPT è§£æä½¿ç”¨è€…è¼¸å…¥çš„æ™‚é–“ç¯„åœï¼Œå›å‚³ start_date, end_date"""
    today_str = datetime.today().strftime("%Y-%m-%d")
    prompt = f"""
    ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„è²¡ç¶“åŠ©ç†ï¼š
    ä½¿ç”¨è€…è¼¸å…¥ä»¥ä¸‹å¥å­ï¼Œè«‹åˆ¤æ–·ä»–æƒ³æŸ¥è©¢çš„æ™‚é–“ç¯„åœã€‚
    å¦‚æœèªªã€Œ1Mã€ã€ã€Œæœ¬æœˆã€ã€ã€Œéå»ä¸€å€‹æœˆã€ã€ã€Œ7Dã€ã€ã€Œä»Šå¤©ã€ç­‰ï¼Œè«‹å›å‚³é–‹å§‹èˆ‡çµæŸæ—¥æœŸï¼Œ
    æ ¼å¼ç‚º YYYY-MM-DDï¼Œä»Šå¤©æ˜¯ {today_str}ã€‚
    å¦‚æœæ²’æœ‰æŒ‡å®šæ™‚é–“ï¼Œè«‹å›å‚³ç©ºå€¼ã€‚
    è¼¸å…¥å¥å­ï¼š{user_input}
    è«‹åªç”¨ JSON æ ¼å¼è¼¸å‡ºï¼Œä¾‹å¦‚ï¼š{{"start_date": "2025-07-13", "end_date": "2025-08-13"}}
    """
    result = call_chatgpt("æ™‚é–“è§£æåŠ©ç†", prompt)
    print(user_input, result)
    try:
        data = json.loads(result)

        # æŠŠç©ºå­—ä¸²è½‰æˆ None
        start_date = data.get("start_date") or None
        end_date = data.get("end_date") or None

        return start_date, end_date
    except:
        return None, None
    




@csrf_exempt
@require_http_methods(["GET"])
def classify_question_api(request):
    def event_stream():
        # è®€å–å‚³å…¥è³‡æ–™
        data = json.loads(request.GET.get("payload", "{}"))
        user_input = data.get("user_input", "").strip()
        selected_modules = data.get("selected_modules", [])
        yield f'data: {json.dumps({"progress": "loding", "result": {"module": "loding","text": "åˆ†æå•é¡Œä¸­", "data": []}}, ensure_ascii=False)}\n\n'
        # 1ï¸âƒ£ åˆ†é¡
        classification_prompt = f"""
        ä½ æ˜¯ä¸€å€‹åˆ†é¡å™¨ï¼Œå¹«æˆ‘åˆ¤æ–·ä¸‹åˆ—å¥å­å¯èƒ½å±¬æ–¼å“ªäº›é¡åˆ¥ï¼š
        æ–°èï¼ˆnewsï¼‰ã€åƒ¹æ ¼ï¼ˆpriceï¼‰ã€å…¶ä»–ç¶“æ¿Ÿæ•¸æ“šï¼ˆotherï¼‰ã€å•å·ï¼ˆquestionnaireï¼‰ã€‚
        å¯ä»¥æœ‰å¤šå€‹ï¼Œè«‹ä»¥é€—è™Ÿåˆ†éš”ï¼›å¦‚æœéƒ½ä¸å±¬æ–¼ï¼Œè«‹å›å‚³ ()ã€‚
        è¼¸å…¥å¥å­ï¼š{user_input}
        è«‹åªè¼¸å‡ºåˆ†é¡çµæœï¼ˆå¦‚ï¼šnews, priceï¼‰
        """
        result = call_chatgpt("ä½ æ˜¯ä¸€å€‹ç²¾æº–çš„åˆ†é¡å™¨", classification_prompt)
        classifications = [c.strip().lower() for c in result.split(",") if c.strip()]
        combined = list(set(selected_modules + classifications))

        module_map = {
            "price": run_price_agent,
            "news": run_news_agent,
            "other": run_other_agent,
            "questionnaire": run_survey_agent
        }
        
        ordered_combined = [k for k in module_map.keys() if k in combined]

        print(ordered_combined)

        # æ¨é€åˆ†é¡çµæœ
        yield f"data: {json.dumps({'classifications': ordered_combined}, ensure_ascii=False)}\n\n"

        # è§£ææ—¥æœŸ
        start_date, end_date = parse_date_range_from_input(user_input)



        # åŸ·è¡Œå„æ¨¡çµ„
        final_answers = []

        for module_name in ordered_combined:
            if module_name in module_map:
                # å…ˆæ¨é€ã€Œç”Ÿæˆä¸­ã€è¨Šæ¯
                yield f'data: {json.dumps({"progress": "loding", "result": {"module": "loding","text": f"{module_name}ç”Ÿæˆä¸­", "data": []}}, ensure_ascii=False)}\n\n'


                # åŸ·è¡Œ module
                answer = module_map[module_name](user_input, start_date, end_date)

                # æ•´ç†çµæœ
                if isinstance(answer, dict):
                    final_answers.append({
                        "module": module_name,
                        "text": answer.get("text", ""),
                        "data": answer.get("extra_data", [])
                    })
                else:
                    final_answers.append({
                        "module": module_name,
                        "text": str(answer),
                        "data": []
                    })

                # æ¯è·‘å®Œä¸€å€‹æ¨¡çµ„å°±æ¨é€çœŸæ­£çµæœ
                print({'progress': module_name, 'result': final_answers[-1]})
                yield f"data: {json.dumps({'progress': module_name, 'result': final_answers[-1]}, ensure_ascii=False)}\n\n"


        if not final_answers:
            final_answers.append({
                "module": "none",
                "text": "æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•è¾¨è­˜æ‚¨çš„å•é¡Œé¡å‹æˆ–æ‚¨æœªé¸æ“‡ç›¸é—œæ¨¡çµ„ã€‚",
                "data": []
            })
            yield f"data: {json.dumps({'progress': 'none', 'result': final_answers[-1]}, ensure_ascii=False)}\n\n"

        yield f'data: {json.dumps({"progress": "loding", "result": {"module": "loding","text": "æ•´åˆå›è¦†ä¸­", "data": []}}, ensure_ascii=False)}\n\n'
        # 5ï¸âƒ£ æ•´åˆå›è¦†
        integrated_summary = ""
        try:
            integration_contents = []
            for f in final_answers:
                data_block = f.get('data')
                module_name = f.get('module', 'unknown')
                if isinstance(data_block, list):
                    data_str = "\n".join([str(d) for d in data_block])
                else:
                    data_str = str(data_block)
                integration_contents.append(f"[{module_name} æ¨¡å¡Š]\n{data_str}")
            integration_prompt_content = "\n".join(integration_contents)

            integration_prompt = f"""
            ä½¿ç”¨è€…å•é¡Œï¼š{user_input}
            ä»¥ä¸‹æ˜¯å¤šå€‹ä¸åŒä¾†æºçš„æ¨¡å¡Šè¼¸å‡ºï¼Œè«‹å¹«æˆ‘æ•´åˆæˆä¸€æ®µè‡ªç„¶èªè¨€çš„å›è¦†ï¼Œ
            ä¿ç•™é‡è¦æ•¸æ“šèˆ‡äº‹ä»¶ï¼Œé‚è¼¯æ¸…æ™°ï¼Œé©åˆç›´æ¥å›è¦†ä½¿ç”¨è€…ï¼š
            {integration_prompt_content}
            """
            integrated_summary = call_chatgpt("ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„è³‡è¨Šæ•´åˆåŠ©ç†", integration_prompt)
        except Exception as e:
            integrated_summary = f"âš ï¸ æ•´åˆå¤±æ•—ï¼š{str(e)}"

        # æœ€å¾Œä¸€æ¬¡æ¨é€ï¼ˆæ•´åˆå›è¦†ï¼‰
        yield f"data: {json.dumps({'integrated_summary': integrated_summary}, ensure_ascii=False)}\n\n"

        # å¯ä»¥å†è£œä¸€å€‹å®Œæˆè¨Šè™Ÿ
        yield "event: end\ndata: done\n\n"

    # SSE å›æ‡‰
    response = StreamingHttpResponse(event_stream(), content_type='text/event-stream')
    response['Cache-Control'] = 'no-cache'
    return response



def chat_view(request):
    return render(request, "chat2.html")




