import os
from typing import Optional
from datetime import datetime
from news.models import Article
from langchain_ollama import OllamaEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document


def initialize_news_vector_store(
    db_location: str = "./vector_db/news",
    model_name: str = "mxbai-embed-large",
    max_docs: int = 100,
) -> Chroma:
    embeddings = OllamaEmbeddings(model=model_name)

    vector_store = Chroma(
        collection_name="crypto_news_articles",
        persist_directory=db_location,
        embedding_function=embeddings,
    )

    # å–å¾—å·²å­˜åœ¨çš„å‘é‡åº« ID
    existing_ids = set(vector_store.get()["ids"])

    # æ‰¾æœ€æ–°çš„æ–°èž
    articles = Article.objects.filter(
        summary__isnull=False, content__isnull=False
    ).order_by("-time")[:max_docs]

    documents, ids = [], []
    for article in articles:
        aid = str(article.id)  # ä½¿ç”¨ Django åŽŸæœ¬çš„ id
        if aid in existing_ids:
            continue  # é¿å…é‡è¤‡
        # åªå­˜ title + summary
        documents.append(Document(
            page_content=f"{article.title}\n{article.summary}",
            metadata={
                "url": article.url,
                "date": str(article.time.date()),  # ISO æ ¼å¼æ–¹ä¾¿æŸ¥è©¢
            },
            id=aid
        ))
        ids.append(aid)

    if documents:
        print(f"ðŸ§  æ–°å¢ž {len(documents)} ç¯‡æ–°èžåˆ°å‘é‡åº«...")
        vector_store.add_documents(documents, ids=ids)
        print("âœ… å‘é‡åº«å·²æ›´æ–°")
    else:
        print("âš¡ å‘é‡åº«å·²æ˜¯æœ€æ–°ï¼Œç„¡éœ€æ›´æ–°")

    return vector_store


def search_news(
    question: str,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    db_path: str = "./vector_db/news",
    embed_model: str = "mxbai-embed-large",
    top_k: int = 5,
):
    #vector_store = initialize_news_vector_store(db_location=db_path, model_name=embed_model) æ¯æ¬¡æœå°‹éƒ½è¦é‡æ•´å‘é‡åº«

    embeddings = OllamaEmbeddings(model=embed_model)
    vector_store = Chroma(
        collection_name="crypto_news_articles",
        persist_directory=db_path,
        embedding_function=embeddings,
    )
    # --- æ™‚é–“éŽæ¿¾æ¢ä»¶ ---
    where = None
    date_filters = []
    if start_date:
        start_timestamp = int(datetime.fromisoformat(start_date).timestamp())
        date_filters.append({"date": {"$gte": start_timestamp}})
    if end_date:
        end_timestamp = int(datetime.fromisoformat(end_date).timestamp())
        date_filters.append({"date": {"$lte": end_timestamp}})
    if date_filters:
        where = {"$and": date_filters} if len(date_filters) > 1 else date_filters[0]
    print(f"ðŸ” æœå°‹æ¢ä»¶ï¼š{where}")

    # --- ç›¸ä¼¼åº¦æœå°‹ ---
    docs = vector_store.similarity_search(
        query=question,
        k=top_k,
        filter=where
    )

    # åªå– title / summary / id
    results = []
    for doc in docs:
        parts = doc.page_content.split("\n", 1)
        title = parts[0] if len(parts) > 0 else ""
        summary = parts[1] if len(parts) > 1 else ""

        results.append({
            "id": doc.id,  # ä½¿ç”¨ Django DB çš„ id
            "title": title,
            "summary": summary,
        })

    return results
