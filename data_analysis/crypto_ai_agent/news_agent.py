# crypto_ai_agent/news_agent.py
import os
from typing import Optional
from news.models import Article
from langchain_ollama import OllamaEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document
from langchain_core.vectorstores import VectorStoreRetriever
from langchain_ollama.llms import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate

def run_news_agent(
    question: str,
    db_path: str = "./vector_db/news",
    embed_model: str = "mxbai-embed-large",
    top_k: int = 5,
) -> str:
    vector_store = initialize_news_vector_store(db_location=db_path, model_name=embed_model)
    retriever: VectorStoreRetriever = vector_store.as_retriever(search_kwargs={"k": top_k})
    docs = retriever.invoke(question)
    results = []
    for doc in docs:
        meta = doc.metadata
        doc_id = getattr(doc, "id", None) or meta.get("id", "")
        results.append(f"{doc.page_content}ï¼ˆ{meta.get('date', '')}ï¼‰(id:{doc_id})")
    
    news_answer = generate_answer("\n".join(results), question)
    return news_answer


def generate_answer(content: str, question: str, model: str = "mistral") -> str:
    prompt = ChatPromptTemplate.from_template("""
    ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„åŠ å¯†è²¨å¹£åˆ†æé¡§å•ï¼Œè«‹å…¨ç¨‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚

    è«‹æ ¹æ“šä»¥ä¸‹è³‡æ–™ï¼Œè©³ç´°å›ç­”é€™å€‹å•é¡Œï¼š
    {question}

    ä»¥ä¸‹æ˜¯ã€Œæ–°èæ‘˜è¦ã€çš„è³‡æ–™ï¼Œæ¯å‰‡æ–°èå¾Œé¢éƒ½æœ‰å°æ‡‰çš„æ–°è ID (id:xxx)ï¼Œè«‹åœ¨ä½ çš„å›ç­”ä¸­æ˜ç¢ºå¼•ç”¨ç›¸é—œæ–°èçš„ ID ä»¥ä¾¿å°æ‡‰ä¾†æºï¼š
    {content}
    """)

    llm = OllamaLLM(model=model)
    chain = prompt | llm
    result = chain.invoke({
        "question": question,
        "content": content
    })
    return result.strip()



def initialize_news_vector_store(
    db_location: str = "./vector_db/news",
    model_name: str = "mxbai-embed-large",
    max_docs: int = 100,
    test_query: Optional[str] = None
) -> Chroma:
    embeddings = OllamaEmbeddings(model=model_name)

    vector_store = Chroma(
        collection_name="crypto_news_articles",
        persist_directory=db_location,
        embedding_function=embeddings,
    )

    if not os.path.exists(os.path.join(db_location, "index")):
        documents, ids = [], []
        articles = Article.objects.filter(
            summary__isnull=False, content__isnull=False
        ).order_by("-time")[:max_docs]

        for article in articles:
            documents.append(Document(
                page_content=f"{article.title}\n\n{article.summary}",
                metadata={
                    "url": article.url,
                    "date": str(article.time),
                },
                id=str(article.id)
            ))
            ids.append(str(article.id))

        print(f"ğŸ§  æ­£åœ¨å‘é‡åŒ– {len(documents)} ç¯‡æ–°è...")
        vector_store.add_documents(documents, ids=ids)
        print("âœ… å‘é‡åº«å·²å»ºç«‹ä¸¦å„²å­˜")

    if test_query:
        retriever = vector_store.as_retriever(search_kwargs={"k": 5})
        results = retriever.invoke(test_query)
        print("ğŸ” æ¸¬è©¦æŸ¥è©¢çµæœï¼š")
        for doc in results:
            meta = doc.metadata
            print(f"- {meta['date']} | {meta['website']} | {doc.page_content}")

    return vector_store